---
title: "Analyse Traces"
author: "Nick Malleson"
date: "13 July 2016"
output:
  html_document: 
    toc: yes
    pandoc_args: [
      "+RTS", "-K64m",
      "-RTS"
    ]
  pdf_document:
    fig_crop: no
    highlight: kate
    keep_tex: yes
    latex_engine: xelatex
    number_sections: yes
fontsize: 10pt
---

An extension to the [map_traces.Rmd](./map_traces.Rmd) program. This has the facility to map traces, but focusses on analysing the difference between matched paths and their equivalent shortest path.

The three different kinds of routes that the script reads are:

 - original traces (the original GPX data)
 - matched routes (the original data matched to OSM routes)
 - shortest paths (the shortest paths the could be used to do the same route)

```{r initialise, echo=FALSE, message=FALSE, warning=FALSE}
# FOR COMPILING RMD ON THE SERVER:
library(knitr)
knitr::opts_knit$set(root.dir = "/home/geonsm/runkeeper/mapmatching-traces/")
setwd("/home/geonsm/runkeeper/mapmatching-traces/")
# The binary file that contains all the traces (exhaustively read in on the server)
TRACES_FILE = "./traces-server-all.RData" # When running from the server



# FOR COMPILING RMD ON NICK's LAPTOP (data on server):
#library(knitr)
#knitr::opts_knit$set(root.dir = "/Users/nick/mapping/projects/runkeeper/mitmount/runkeeper/mapmatching-traces/")
#setwd("/Users/nick/mapping/projects/runkeeper/mitmount/runkeeper/mapmatching-traces/")
#TRACES_FILE = "~/research_not_syncd/mapping_local/projects/runkeeper/mitmount/runkeeper/mapmatching-traces/traces-server-all.RData" # When running on laptop (all data on server)



# FOR WORKING LOCALLY (e.g. testing stuff)
#setwd('~/research_not_syncd/git_projects/surf/projects/BreezeRoutes/traces')
#TRACES_FILE = "./traces-temp.RData"

# Paths to the original files, shortest paths, and matched paths
path.org =      "./gpx/"
path.matched =  "./gpx-matched/"
path.shortest = "./gpx-shortest/"

library(GISTools)
#library(rgeos)    # For things like gIntersects
library(rgdal)     # For reading shapefiles
#library(raster)    # For creating regular grids or converting from SpatialPixelsDataFrame to raster
#library(plyr)     # For counting and aggregating
#library(tmap)     # For thematic maps
#library(classInt) # Jenks natural breaks
#library(png)      # For loading pngs after they have been written
#library(grid)     # so that they can be embedded in knitted documents
#library(spdep)    # For doing the spatial regression, contiguity matrices, etc.
#library(GWmodel)  # For geographically weighted regression (GWR)
#library(MASS)     # For stepwise regression (stepAIC())
#library(pander)   # For printing tables nicely
#library(MVN)      # For testing for multivariate normality (MVN)
#library(stats)     # For a-spatial aggregatiion (aggregate)
#library(ggplot2)   # For density scatter plot

#library(hexbin)    # For hexagonal density scatter plots in ggplot
#library(gridExtra) # To put two graphs next to each other in ggplot
library(plotKML)   # For reading GPX files
library(OpenStreetMap) # For plotting OSM basemaps
Sys.setenv(MC_CORES=6) # Run on n cores (I'm not sure which of these
options("mc.cores"=6L) # is correct).
library(parallel) # For ruonning things in parallel (e.g. mclapply())
library(plotKML)   # For reading GPX files
library(data.table) # For adding up distances per user (data.table())
```


# Function to map a trace

It is sometimes useful to visualise a particualr trace. This has come from [map_traces.Rmd](./map_traces.Rmd) - see that file for proper documentation.

```{r map.trace.function }

expanded.bb <- function(bounds) {
  
  bb <- bbox(bounds)
  # Make the bounding box x % larger to make sure none of the map is clipped
  width = bb[1,2] - bb[1,1]
  height = bb[2,2] - bb[2,1]
  x <- 0.10 # 20 % larger in total
  bb[1,1] = bb[1,1] - (width*x)
  bb[1,2] = bb[1,2] + (width*x)
  bb[2,1] = bb[2,1] - (height*x)
  bb[2,2] = bb[2,2] + (height*x)
  return(bb)
}

# A convenience for plotting a trace given a filename relative to cwd
map.file <- function(filename) {
  print(paste("Mapping GPX file",filename))
  # Create SpatialLinesDataFrames for the track
  track <- readOGR(dsn=filename, layer="tracks", verbose=FALSE )  
  # Project to WGS 84 / Pseudo Mercator (epsg:3857) for OSM
  track.merc <- spTransform(track, CRS("+init=epsg:3857"))
  
  bb <- expanded.bb(track@bbox)

  # Get an OSM basemap (coordinates are upper-left and lower-right)
  basemap <- openmap(
    upperLeft = c(bb[2,2],bb[1,1]), # Upper-left (lat,lon) (y,x)
    lowerRight = c(bb[2,1], bb[1,2]), # Lower-right
    type='osm', zoom=17)
  
  par(mfrow=c(1,1))
  plot(basemap)
  plot(track.merc, col='blue', lwd=3)
  title(paste("Track for\n",f), cex=0.5 )
}

# A convenience to call the plotting function defined below (just pass in the list index for the routes)
map.index <- function(N, osm=TRUE) {
  map.trace(orig[[N]], matched[[N]], shortest[[N]], osm=osm)
}

map.trace <- function(orig, matched, short, osm=TRUE) {
  # Get a bounding box for the whole dataset to make sure plots are big enough
  # Need to do this before projecting otherwise openmap() doesn't work (not sure why)
  bb <- expanded.bb(orig@bbox)
  
  # Project to WGS 84 / Pseudo Mercator (epsg:3857) for OSM
  matched.merc <- spTransform(matched, CRS("+init=epsg:3857"))
  orig.merc    <-   spTransform(orig,    CRS("+init=epsg:3857"))
  short.merc <- spTransform(short,    CRS("+init=epsg:3857"))
  
  # Get an OSM basemap (coordinates are upper-left and lower-right)
  if (osm) {
    basemap <- openmap(
      upperLeft = c(bb[2,2],bb[1,1]), # Upper-left (lat,lon) (y,x)
      lowerRight = c(bb[2,1], bb[1,2]), # Lower-right
      type='osm', zoom=17)
  }
  
  par(mfrow=c(1,1))
  if (osm) {
    plot(basemap)
  }
  else {
    plot(orig.merc, col='blue', lwd=3)
  }
  #title(paste("Routes for route",N), cex=0.5 )
  plot(orig.merc, col='blue', lwd=3, add=T)
  plot(matched.merc, lwd=3, col='black', add=T)
  plot(short.merc, col='green', lwd=3, add=T)
  
}

# Get the USER ID from an original gpx file
read.userid <- function(filename) {
  text <- tryCatch( 
    { readLines(filename) },
    error=function(cond) {
      message(paste("Could not read file for username: ", filename, '. Message is:', cond))
      return(-1)
    }
  ) # tryCatch
  if (text==-1) {
    return(-1)
  }
  result <- grep('userId=[A-z0-9]+', text, value=TRUE) # Find the bit with the User ID
  if (length(result)==0) {
    warning(paste("No match for user im file",filename))
    return (-1)
  }
  # Match looks ok, return the userid part.
  uid <- substring(result,8)
  #print(paste("Got UID: ",uid))
  return(uid)
}

```

# Read the Data

Read all of the traces and store in memory. Only read 'matched' traces because those will definitely have an original trace and a shortest path. Not all original traces have been matched by the MapMatcher program.


```{r readTraces}

if (!file.exists(TRACES_FILE)) {
  # Vectors that will contain all of the paths and associated information.
  orig <- list() 
  matched <- list()
  shortest <- list()
  orig.ma <- list()  # Projected versions
  matched.ma <- list()
  shortest.ma <- list()
  userid <- list()

  # Read files in the 'matched' directory. We're only interested in mapping routes that have been matched 
  # (and if they've ben matched then they probably also have a companion shortest path).
  file.names <- dir(path.matched, pattern =".gpx")
 
  #for(i in 1:1000){
  for(i in seq(length(file.names))){
    start.time <- proc.time()[['elapsed']]
    f <- substr(file.names[i], 1, nchar(file.names[i])-12) # The name of the file without the '-matched.gpx' extension.
    f.orig <-    paste(path.org,      f, ".gpx", sep="")
    f.matched <- paste(path.matched,  f, "-matched.gpx", sep="") # The matched file (f531b5395-matched.gpx)
    f.shortest<- paste(path.shortest, f, "-shortest.gpx", sep="") # The shortest path (f531b5395-shortest.gpx)
    print(paste("Reading file (",i,")",f))
    
    # Create SpatialLinesDataFrames for each track, project them to good projection for MA (Albers) add them to the lists
    # (https://www.arcgis.com/home/item.html?id=d075ba0b6b5e4d71b596e882493f7789)
    # Read the three required files simultaneously in parallel
    read.data <- mclapply(
      list("orig"=f.orig, "matched"=f.matched, "shortest"=f.shortest), 
      FUN=function(x){
        # Read the GPX and convert the $tracks to a dataframe. All wrapped in a try-catch in case file can't be read
        gpx <- as.data.frame(
          tryCatch(
            {
              readGPX(x, metadata = TRUE, bounds = TRUE,waypoints = FALSE, tracks = TRUE, routes = FALSE)$tracks
            },
            error=function(cond) {
              message(paste("Could not read file: ", x, '. Message is:', cond))
              return(NULL)
            },
            warning=function(cond) {
              message(paste("Could not read file: ", x, '. Message is:', cond))
              return(NULL)
            }
          ) #trycatch
        ) #as.data.frame
        # Work out where x,y coords are
        if ('GraphHopper.lon' %in% colnames(gpx) ) {
          xcor <- gpx$GraphHopper.lon
          ycor <- gpx$GraphHopper.lat
        } else {
          xcor <- gpx$lon
          ycor <- gpx$lat
        }
        
        lines <- SpatialLines(
          list(Lines(lapply(list(cbind(xcor, ycor)), Line), ID="a")),
          proj4string = CRS("+init=epsg:4326"))
        return(lines)
      }
    )
    orig[[i]]    =  read.data[['orig']]
    matched[[i]] =  read.data[['matched']]
    shortest[[i]] = read.data[['shortest']]
    
    transformed <- mclapply(
      list("orig.ma"=orig[[i]], "matched.ma"=matched[[i]], "shortest.ma"=shortest[[i]]),
      FUN = function(x) { return(spTransform(x, CRS("+init=epsg:5070")) ) }
    )
    orig.ma[[i]] =    transformed[['orig.ma']]
    matched.ma[[i]] = transformed[['matched.ma']]
    shortest.ma[[i]] =transformed[['shortest.ma']]
   
    # To get the user id we need to re-read the original gpx file and parse it manually. The
    # readGPX function doesn't keep the meta-data, and readOGR is too slow.
    uid <- read.userid(f.orig)
    if (uid == -1) {
      warning(paste("Not able to get the user ID for route (",i,")", f ) )
      uid = "NA"
    }
    userid[[i]] = uid
    
    # OLD WAY OF GETTING UID WHEN SING readOGR
    ## Get the user ID. This needs to be done by parsing the description as readOGR didn't bring in the metadata properly)
    ## Split the string on '\n' (fixed=T means treat this as it is, not as a regex), and take the 6th element
    ##which should be a string like: userId=857ac8242e49159c7abb25bb458a7bc9. Then just get the id from that
    #uid_str <- strsplit(as.character(orig[[i]]@data$desc), '\n', fixed=T)[[1]][6] 
    #uid_split <- strsplit(uid_str, '=')[[1]]
    #uid = uid_split[2] # Second element after splitting on '='
    #if (uid_split[1]!="userId") {
    #  warning(paste("Not able to get the user ID for route (",i,")", f ) )
    #  uid = "NA"
    #}
    #userid[[i]] = uid
    
    print(paste("\t.. finished in",round(proc.time()[['elapsed']]-start.time,digits=2),"secs"))
    
  }# for files
    
  
  if (length(matched) != length(orig) || length(matched) != length(shortest) || length(matched) != length(userid)) {
    warning("For some reason there are different numbers of original, matched, and shortest paths.")
  }
  
  # Save the traces
  save(orig, matched, shortest, orig.ma, matched.ma, shortest.ma, userid, file=TRACES_FILE)

} else {
  print(paste("Loading traces from file", TRACES_FILE))
  load(TRACES_FILE)
}

```

Read `r length(matched)` matched traces, `r length(orig)` original traces, and `r length(shortest)` shortest paths.

# Filter Bad Matches

Earlier in the data anlysis process, clean traces were filtered out (see `2-breeze-analyse_data.Rmd`). This removed traces that, e.g. were too short to be useful. Now clean out traces that have not been matched to a given accuracy threshold (i.e. the shortest and matched traces are substantially different.)

Need to decide what 'outliers' are. Try the mean+1sd (red lines) and Q3+1.5*IQR (blue lines).

```{r findBadMatchedPaths, fig.height=20 }

# Calculate the lenths of the paths
orig.lengths    <-  unlist(mclapply(orig.ma, FUN=gLength))
matched.lengths  <- unlist(mclapply(matched.ma, FUN=gLength))
shortest.lengths <- unlist(mclapply(shortest.ma, FUN=gLength))

# Calclulate the path differences between shortest and matched
abs.diff <- mcmapply( # Absolute distance
  FUN=function(a,b) {return(abs(a-b))},
  orig.lengths, matched.lengths
)
rel.diff <- mcmapply( # Absolute relative (percentage) difference
  FUN=function(a,b) {return(abs(100*(a-b)/a))},
  orig.lengths, matched.lengths
)
diff <- mcmapply( # Difference
  FUN=function(a,b) {return(a-b)},
  orig.lengths, matched.lengths
)

summary(diff)
summary(abs.diff)
summary(rel.diff)

# Make margins smaller temporarily
margins <- par("mar")
par(mfrow=c(5,2), mar = rep(2, 4))
boxplot(diff, main="Difference between matched\nand original paths) (m)")
boxplot(diff, main="(short axis)", ylim = c(-500,400))
boxplot(abs.diff, main="Abslute Difference (m)")
boxplot(abs.diff, main="(short axis)", ylim = c(0,1000))
boxplot(rel.diff, main="Abslute Relative (percentage) Difference (m)")
boxplot(rel.diff, main="(short axis)", ylim = c(0,200))

hist(abs.diff, breaks="Scott", main="Histogram of absolute difference", xlab="Difference (m)")
abline(v=mean(abs.diff)+1*sd(abs.diff), col="red")
abline(v=quantile(abs.diff)[4]+(1.5*IQR(abs.diff)), col="blue")

hist(abs.diff, breaks="Scott", xlim=c(0,3000), main="(short axis)")
abline(v=mean(abs.diff)+1*sd(abs.diff), col="red")
abline(v=quantile(abs.diff)[4]+(1.5*IQR(abs.diff)), col="blue")

hist(rel.diff, breaks="Scott", main="Histogram of relative difference", xlab="Percentage Difference (m)")
abline(v=mean(rel.diff)+1*sd(rel.diff), col="red")
abline(v=quantile(rel.diff)[4]+(1.5*IQR(rel.diff)), col="blue")

hist(rel.diff, breaks="Scott", xlim=c(0,200), main="(short axis)", xlab="Percentage Difference (m)")
abline(v=mean(rel.diff)+1*sd(rel.diff), col="red")
abline(v=quantile(rel.diff)[4]+(1.5*IQR(rel.diff)), col="blue")

par(mar=margins)

```

It looks like the mean is pulled a lot by very severe outliers in the top end -- one trace has a difference between the original and the matched of `r max(abs.diff)`m! There are only `r length(which( abs.diff>(mean(abs.diff)+2*sd(abs.diff)) | rel.diff>(mean(rel.diff)+2*sd(rel.diff))))` traces that would be removed using the mean as the definition as an outlier, but `r length(which(abs.diff>(quantile(abs.diff)[4]+(1.5*IQR(abs.diff)))|rel.diff>(quantile(rel.diff)[4]+(1.5*IQR(rel.diff)))))` that would be removed using the quartile definition. This is quite a lot (too many) but will do for now.


```{r filterBadMatchedPaths}

#bad.indices <- which( abs.diff>(mean(abs.diff)+2*sd(abs.diff)) | rel.diff>(mean(rel.diff)+2*sd(rel.diff)))
bad.indices <- which( 
  abs.diff>(quantile(abs.diff)[4]+(1.5*IQR(abs.diff))) | 
  rel.diff>(quantile(rel.diff)[4]+(1.5*IQR(rel.diff)))
  )

orig <- orig[-bad.indices]
matched <- matched[-bad.indices]
shortest <- shortest[-bad.indices]
orig.ma <- orig.ma[-bad.indices]
matched.ma <- matched.ma[-bad.indices]
shortest.ma <- shortest.ma[-bad.indices]
userid <- userid[-bad.indices]

# Delete old variables
rm(abs.diff, bad.indices, diff, rel.diff)

```

After filtering, there are `r length(matched)` matched traces, `r length(orig)` original traces, and `r length(shortest)` shortest paths.

These were created by `r length(unique(unlist(userid)))` separate users.

This is a god point to create a single SpatialLines object from the discrete Lines (traces).

```{r createSingleLine}
# Use a consistent projection
PROJ4STRING <- matched[[1]]@proj4string

# Begin by creating a single SpatialLines object of all matched lines (https://stackoverflow.com/questions/18023462/how-to-unlist-spatial-objects-and-plot-altogether-in-r)

#  Get the Lines objects which contain multiple 'lines'
lines.objects <- unlist( mclapply( matched , function(x) `@`(x , "lines") ) )
# Give each an ID based on its index
for (i in seq(1,length(matched))) { lines.objects[[i]]@ID <- as.character(i) }

# Make a SpatialLines object from all of those lines
all.routes <- SpatialLines(lines.objects, proj4string = PROJ4STRING)

#  Also make one bg SpatialLines object for mapping. Begin by extracting the individual 'lines'
individual.lines <- mclapply( lines.objects , function(y) `@`(y,"Lines") )
#  Combine them into a single SpatialLines object. This is good for quick plotting etc.
all.routes.oneline <- SpatialLines( list( Lines( unlist( individual.lines ) , ID = 1 ) ), proj4string = PROJ4STRING )
#writeOGR(SpatialLinesDataFrame(all.routes.oneline, data=data.frame(c(1)) ), dsn=".", layer="all_routes_oneline", driver="ESRI Shapefile")
rm(individual.lines, lines.objects)

par(mfrow=c(1,1))
plot(all.routes.oneline, axes=T, main="All Traces")

# Useful to analyse in a GIS
#writeOGR(SpatialLinesDataFrame(all.routes.oneline, data=data.frame(1)), dsn=".", layer="all_routes.shp",driver="ESRI Shapefile", overwrite_layer=TRUE)

```


# Compare path distances

## Aggregate comparisons

### Actual paths v.s. shortest path

Look at the differences in the lengths between actual (matched) paths and shortest paths. The matched and original are very similar, and the shortest are shorter :-).

```{r compareLengthsHist1 }
# Need to recalculate lengths after filtering
orig.lengths    <-  unlist(mclapply(orig.ma, FUN=gLength))
matched.lengths  <- unlist(mclapply(matched.ma, FUN=gLength))
shortest.lengths <- unlist(mclapply(shortest.ma, FUN=gLength))

par(mfrow=c(1,3))
ylim <- c(0,10000)
xlim <- c(0,8000)

hist(orig.lengths,     breaks='Scott', xlim=xlim, ylim=ylim )
hist(matched.lengths,  breaks='Scott', xlim=xlim, ylim=ylim )
hist(shortest.lengths, breaks='Scott', xlim=xlim, ylim=ylim )
```

```{r compareLengthsHist2 }
par(mfrow=c(1,1))
d <- density(shortest.lengths, kernel="gaussian") # Remember first density plot so parameters can be reused
plot(d, col="blue", main="Trip distance distribution")

lines(density(orig.lengths, kernel="gaussian", bw=d$bw), col="grey")
lines(density(matched.lengths, kernel="gaussian", bw=d$bw), col="black")
legend("topright", c('Shortest', 'Original', 'Matched'), col=c('blue', 'grey', 'black'),lty=1)

```

```{r compareLengthsBoxPlot}
par(mfrow=c(1,1))
boxplot(list("Original"=orig.lengths,"Matched"=matched.lengths,"Shortest"=shortest.lengths),ylim=c(0,5000), main="Path distances (short y axis)", ylab="Path distance")
```

### Hausdorff distances

Look at the Hausdorff distances between the paths. This quantifies how similar the paths are.

```{r hausdorffDistancesHist1} 
# Run using lapply as above. This is just slightly more complicated because the distance function requires two 
# arguments as it compares two lines. mapply does this. The function comes first, followed by the arguments 
haus.orig.matched <- unlist(
  mcmapply(
    FUN=gDistance, # Function to calcuate the distance
    orig.ma, matched.ma, # First two arguments
    MoreArgs=list(byid=FALSE, hausdorff=TRUE) # Some other named argments
  )
)
haus.matched.shortest <- unlist(
  mcmapply(
    FUN=gDistance, # Function to calcuate the distance
    matched.ma, shortest.ma, # First two arguments
    MoreArgs=list(byid=FALSE, hausdorff=TRUE) # Some other named argments
  )
)
par(mfrow=c(1,2))
xlim=c(0,1000)
ylim=c(0,10000)
hist(haus.orig.matched, main="Hausdorff distance\nOriginal v.s. Matched", xlab="Distance", breaks="Scott",xlim=xlim,ylim=ylim)
hist(haus.matched.shortest, main="Hausdorff distance\nMatched v.s. Shortest", xlab="Distance",  breaks="Scott",xlim=xlim,ylim=ylim)

```

```{r hausdorffDistancesHist2} 
par(mfrow=c(1,1))
d <- density(haus.orig.matched, kernel="gaussian")
plot(d, main="Hausdorff distance distribution", col="grey", xlim=c(0,2000))
lines(density(haus.matched.shortest, kernel="gaussian", bw=d$bw), col="black")
legend("topright", c('Matched - Original','Matched - Shortest'), lty=1, col=c('grey','black'))

```

```{r hausdorffDistances2} 
par(mfrow=c(1,1))
boxplot(list("Matched<->Original"=haus.orig.matched, "Matched<->Shortest"=haus.matched.shortest), main="Hausdorff Distances (short y axis)",ylim=c(0,1000))

```



## Disaggregate (shortest-matched comparisons)

### Difference between shortest and matched (normalised)

Calculate the normalised difference between the shortest and matched paths. The plot the distribution of these differences.

```{r compareDisaggDistsances, fig.width=10, fig.height=10 }

absolute.diffs <- matched.lengths - shortest.lengths
# Normalise to range 0->1
absolute.diffs.n1 <- ( absolute.diffs - min(absolute.diffs) ) / (max(absolute.diffs) - min(absolute.diffs))
# Normalise by dividing by the shortest path
absolute.diffs.n2 <- absolute.diffs / shortest.lengths

par(mfrow=c(2,2))
hist(absolute.diffs.n1, breaks="Scott", xlab="Difference", main="Absolute trip distance differences.\nNormalised to range 0->1 ")
hist(absolute.diffs.n1, breaks="Scott", xlab="Difference", xlim=c(0.05,0.15), main="(shorter x axis)" )

hist(absolute.diffs.n2, breaks="Scott", xlab="Difference", main="Absolute trip distance differences.\nNormalised by dividing by shortest path")
hist(absolute.diffs.n2, breaks="Scott", xlab="Difference", xlim=c(0,2), main="(shorter x axis)" )

```

Try plotting the most different matched routes - those that are Q3+1.5*IQR meters (`r quantile(absolute.diffs)[4] + ( 2 * IQR(absolute.diffs))`m) longer than their shortest counterparts)

```{r visualiseDifferentPaths, fig.width=15}
par(mfrow=c(1,2))

plot(all.routes, xlim=c(-71.2,-71.0), ylim=c(42.2,42.45), 
     main="Matched routes with very different \n shortest paths (absolute difference)")
plot(all.routes[ which(absolute.diffs>quantile(absolute.diffs)[4]+(2*IQR(absolute.diffs)) ) ],
    col="blue", add=T )

plot(all.routes,  xlim=c(-71.2,-71.0), ylim=c(42.2,42.45), 
     main="(Normalised by shortest path)")
plot(all.routes[ which(absolute.diffs.n2>quantile(absolute.diffs.n2)[4]+(2*IQR(absolute.diffs.n2)) ) ],
     col="blue", add=T )

```

_Nothing particularly interesting there so far .._

### Hausdorff and actual difference in distances travelled

Finally compare the Hausdorff and relative distances travelled in one plot (for the paper).

```{r hausdorff.and.actual.difference, fig.height=15}

par(mfrow=c(2,1))

XXXX HERE - REDRAW WITH Y AXIS THAT DOESN'T LEAVE THE PAGE

# Actual distance

rel.diff.distance <- ( matched.lengths - shortest.lengths ) / matched.lengths
hist(rel.diff.distance, breaks="Scott", xlim=c(0,1), ylim=c(0,3000), main="Relative (proportional) difference in\ndistances travelled", xlab="Relative difference (matched trace - shortest trace) (m)")

# Hausdorff
hist(haus.matched.shortest, breaks="Scott", xlim=c(0,1000), ylim=c(0,10000), main="Hausdorff path differences", xlab="Hausdorff difference (matched - shortest)")

# Both on same graph

#d <- density(haus.matched.shortest, kernel="gaussian")
#plot(d, col="blue", xlim=c(0,1500), ylim=c(0,0.006), main="")
#lines(density(abs.diff.distance, kernel="gaussian", bw=d$bw), col="black")
#legend("topright", c('Hausdorff Distance','Actual Difference'), lty=1, col=c('blue','black'))

# Do a pdf for the paper
pdf(file="hausdorff_and_actual_difference.pdf", width = 7, height = 11.69)
par(mfrow=c(2,1))
rel.diff.distance <- ( matched.lengths - shortest.lengths ) / matched.lengths
hist(rel.diff.distance, breaks="Scott", xlim=c(0,1), ylim=c(0,3000), main="Relative (proportional) difference in\ndistances travelled", xlab="Relative difference (matched trace - shortest trace) (m)")
hist(haus.matched.shortest, breaks="Scott", xlim=c(0,1000), ylim=c(0,10000), main="Hausdorff path difference", xlab="Hausdorff difference (m)")
dev.off()


```

## Similarity metrics

Look at the number of road segments that are shared by each path. To do this:

 1. Create a vector of all segments.
 1. For each path, create a vector (or string) that describes whether (1) or not (0) the path contains a particular segment. Most entries will be 0. This is similar to the vectorisation performed in natural language processing.

XXXX

 - graph similarity metrics - e.g. convert to string (0,1) and compare strings (lots of metrics available)
 






# Explore User distances

Look at the range of distances travelled by individual users. Is there some regularity?

First the number of traces per user.

```{r userDistances}
# Improved histogram for integers (https://mikelove.wordpress.com/2011/03/30/r-one-liner-histogram-for-integers/)
int.hist = function(x,ylab="Frequency",...) {
  barplot(table(factor(x,levels=min(x):max(x))),space=0,xaxt="n",ylab=ylab,...);axis(1)
}

# First find the frequency distribution of trips per user

uid.freq = as.data.frame(table(as.factor(unlist(userid))))
int.hist(uid.freq$Freq, main="Traces per user", xlab="Number of traces", ylab="Frequency (number of users)")
```

Now look at the distributions of mean and standard deviations

```{r userDistancesDist}

# A list of users and their total distances. Uses data.table. https://stackoverflow.com/questions/11782030/sum-by-distinct-column-value-in-r
uid.total.dists <- data.table(
  "userid"=unlist(userid), 
  "orig.lengths"=unlist(orig.lengths), 
  "matched.lengths"=unlist(matched.lengths), 
  "shortest.lengths"=unlist(shortest.lengths), 
  key="userid")
# Now sum that data table
uid.total.dists <- uid.total.dists[,list(sum(orig.lengths), sum(matched.lengths), sum(shortest.lengths), (.N) ), by=userid]
names(uid.total.dists) <- c("userid", "orig", "matched", "shortest", "N")

par(mfrow=c(1,2))
boxplot(list(
  "Orig"=uid.total.dists$orig/uid.total.dists$N, 
  "Shortest"=uid.total.dists$matched/uid.total.dists$N,
  "Matched"=uid.total.dists$matched/uid.total.dists$N),
  main="Average distances\ntravelled per user (m)",
  ylab="Mean distance travelled (m)")
boxplot(list(
  "Orig"=uid.total.dists$orig/uid.total.dists$N, 
  "Shortest"=uid.total.dists$matched/uid.total.dists$N,
  "Matched"=uid.total.dists$matched/uid.total.dists$N),
  main="(short y axis)",
  ylim=c(0,3000))

```


# Quantify Symmetry

Replicate the work in Phithakkitnukoon and Ratti (2011):

Phithakkitnukoon, Santi, and Carlo Ratti (2011). Inferring Asymmetry of Inhabitant Flow Using Call Detail Records. _Journal of Advances in Information Technology_ 2(4). http://ojs.academypublisher.com/index.php/jait/article/view/jait0204239249.

## Process:

  - Split area into grid cells
  - Calculate transition matrix, M, (shows flows between cells)
  - Calculate in- and out-flows for cells. Symmetrical?
  - Calculate symmetry of M
  - Look at places that are not symmetrical.
  
**For the similarity analysis only work with the matched traces**
  
## Define study area

Need to define the study area (fairly arbitrary)

```{r defineStudyArea}

# Define the study area (farily arbitrary)
study.area.bb <- all.routes.oneline@bbox
study.area.bb[1,1] <- -71.2 # x min
study.area.bb[1,2] <- -71.0 # x max
study.area.bb[2,1] <-  42.26 # y min
study.area.bb[2,2] <-  42.42  # y max
#study.area.bb[1,1] <- -7920375 # x min
#study.area.bb[1,2] <- -7908295 # x max
#study.area.bb[2,1] <-  5206223 # y min
#study.area.bb[2,2] <-  5221410 # y max

study.area.coords <- rbind(
  cbind(study.area.bb[1,1],study.area.bb[2,1]),
  cbind(study.area.bb[1,1],study.area.bb[2,2]),
  cbind(study.area.bb[1,2],study.area.bb[2,2]),
  cbind(study.area.bb[1,2],study.area.bb[2,1])
)

# Make a polygon from the bounding box
study.area <- SpatialPolygons(list(Polygons(list(Polygon(study.area.coords)), ID = 1)), proj4string = PROJ4STRING)

#writeOGR(SpatialPolygonsDataFrame(study.area, data=data.frame(c(1))) , dsn = "./", layer="study_area", driver="ESRI Shapefile")

par(mfrow=c(1,1))
plot(all.routes.oneline, axes=T, main="All Traces and the Study Area")
points(study.area.coords, col="red")
plot(study.area, col=rgb(1, 0, 0,0.3), add=T)

```

## Make the grid (will become the transition matrix)

Now create a regular grid that covers the study area. This will be used to create the transition matrix

```{r makeGridForTransitionMatrix, fig.width=15}

# The number of cells per row or column
num.cells <- 20
total.cells <- num.cells ** 2

# Create the grids - adapted from Brunsdon & Comber (2015, p150)
cell.width <-  (study.area.bb[1,2] - study.area.bb[1,1]) / num.cells
cell.height <- (study.area.bb[2,2] - study.area.bb[2,1]) / num.cells

#cell.areas <- c(cell.areas, (cell.width * cell.height) ) # Also remember the cell area for later

centre.x <- study.area.bb[1,1] + ( cell.width / 2 )
centre.y <- study.area.bb[2,1] + ( cell.height / 2 )

# Make the grid
grd <- GridTopology(
  cellcentre.offset = c(centre.x, centre.y), # No offset, the grid will just cover all the points
  cellsize = c(cell.width, cell.height),
  cells.dim = c(num.cells, num.cells)
  )

# Convert it into a polygons data frame, and give each cell it's x and y locations in the matrix (-1 initially)
grid <- SpatialPolygonsDataFrame(
  as.SpatialPolygons.GridTopology(grd),
  data = data.frame("ID"=rep.int(-1,total.cells),"CellX"=rep.int(-1,total.cells),"CellY"=rep.int(-1,total.cells)),
  match.ID = FALSE
  )
proj4string(grid) <- PROJ4STRING
rm(grd)
# Set the ID properly and keep a record of the (x,y) coordinates and associated ID
grid.ids <- matrix(data=0, nrow=num.cells, ncol=num.cells)
cellcount <- 1
for (rowcount in seq(1,num.cells)) {
  for (colcount in seq(1,num.cells)) {
    grid@data[cellcount,]$CellX <- colcount
    grid@data[cellcount,]$CellY <- rowcount
    grid@data[cellcount,]$ID <- cellcount
    grid.ids[rowcount,colcount] <- cellcount
    cellcount <- cellcount + 1
  }
}

par(mfrow=c(1,1))
plot(grid, border='blue', main="Routes and the grid")
plot(all.routes.oneline, add=T)

#plot(grid, border='blue', main="Grid labels")
#polygonsLabel(grid, paste('(',grid$CellX,',',grid$CellY,')', sep=""), cex=0.4 )

```

The grid consists of `r num.cells` cells, with a mean square area of `r mean(raster::area(grid))/(1000**2)` km^2^.




## Calculate transition matrix, M

Process:

 1. Iterate over each cell
    1. Clip the traces within the cell
    1. Iterate over each (sub) trace
      - Identify one of three possible conditions

      1. The line begins in the cell
        - Increment the _departure_ count, for the appropriate direction (N,S,E,W)
      1. The line passes through the cell
         - Increment the _departure_ count for the appropriate direction (N,S,E,W)
      1. The line ends in the cell
         - Do nothing.
      1. The line is wholly contained within the cell
         - XXXX WHAT DO DO?! Check Ratti paper


The following functions do the analysis. They're defined here and then executed in the next chunk.

### Define matrix functions


```{r defineTransitionMatrixFunctions}

make.line <- function(x1, x2, y1, y2, p4s) {
  # This does Line -> Lines -> SpatialLines (overkill right?!?)
  return(
    SpatialLines(
      list(Lines(
        list(Line( cbind(c(x1, x2), c(y1, y2)) )),
        ID="a"
      )),
      proj4string = p4s
    )
  )
}

#' Takes a cell and a point and works out whether the point lies on the north, south, east or west
#' corner of the cell (or none of those)
#' 
#' @param the.cell 
#' @param the.point
#' @return a vector of size four with TRUE/FALSE for whether the point lies on the north, east,
#' south, or west edge of the cell.
find.nsew <- function(the.cell,the.point) {
  # Make lines for the four squares of the cell to calculate the intersect.
  north <- make.line(
    the.cell@bbox['x','min'], the.cell@bbox['x','max'], 
    the.cell@bbox['y','max'], the.cell@bbox['y','max'],
    the.point@proj4string)
  east <- make.line(
    the.cell@bbox['x','max'], the.cell@bbox['x','max'], 
    the.cell@bbox['y','min'], the.cell@bbox['y','max'],
    the.point@proj4string)
  south <- make.line(
    the.cell@bbox['x','min'], the.cell@bbox['x','max'], 
    the.cell@bbox['y','min'], the.cell@bbox['y','min'],
    the.point@proj4string)
  west <- make.line(
    the.cell@bbox['x','min'], the.cell@bbox['x','min'], 
    the.cell@bbox['y','min'], the.cell@bbox['y','max'],
    the.point@proj4string)
  return( c(
    gIntersects(north,the.point),
    gIntersects(east,the.point),
    gIntersects(south,the.point),
    gIntersects(west,the.point)
    #the.cell@bbox['y','max']==the.point@bbox['y','max'], #N
    #the.cell@bbox['y','min']==the.point@bbox['y','min'], #S
    #the.cell@bbox['x','max']==the.point@bbox['x','max'], #E
    #the.cell@bbox['x','min']==the.point@bbox['y','min']  #W
    ) )
}

#' Takes a cell (a SpatialPolygonsDataFrame), calculates whether it has lines passing through it,
#' and returns the cell with this information in a list
#' 
#' @param cell The cell to analyse
#' @param the.traces All of the traces that might pass through the cell
#' @param run.gc Whether to run gc() before returning
#' @return A list, with the following items
#'   "cell": the cell object itself (a SpatialPolygonsDataFrame),
#'   "departure.count": a vector of size four, showing the number of traces that left this cell from the 
#'       north, east, south, west directions.
#'   "starting.count": the number of traces that begin in this cell
#'   "ending.count": the number of traces that end in this cell
#'   "wholly.contained": the number of traces that are wholly contained in this cell
calc.cell <- function(cell, the.traces, run.gc=FALSE, plot=TRUE) {
  
  # Remember the number of lines entering and leaving the cell, and their direction.
  # Store for values for each one, representing whether the line has crossed the n,s,e, or w boundary
  departure.count <- c(0,0,0,0) # The number of traces leaving this cell and their direction
  
  # Also useful to remember the number of lines starting and finishing here. Don't need direction with 
  # these though as this is captured in the vectors above
  starting.count <- 0
  ending.count   <- 0
  wholly.contained <- 0 # The line starts and ends in the cell without going through another cell.
  total.intersection <- 0 # The total number of lines that intersect the cell
  
  # First find the traces that intersect the cell
  intersecting <- gIntersects(the.traces, cell, byid = TRUE) 
  
  # For info, store the number of lines that intersect this cell
  total.intersection <- length(which(intersecting))
  
  
  # Only continue if some traces intersect
  if (length(which(intersecting))>0) {
    
    # Clip the lines in this cell. For some reason gIntersection sometimes breaks whe the intersecting
    # lines are passed directly (as below) so instead pass each line individually in a separate call
    #lines.in.cell <- gIntersection(the.traces[which(intersecting)], cell, byid=TRUE) # Creates a list of SpatialLines objects
    
    list.of.cells <- lapply(seq(1,length(the.traces[which(intersecting)])), 
                            FUN = function(i,g) { return(g[i,]) }, g=the.traces[which(intersecting)])
    lines.in.cell <- lapply(list.of.cells, FUN=gIntersection, spgeom2=cell, byid=TRUE)
      #tryCatch(
      #{
      #  gIntersection(the.traces[which(intersecting)], cell, byid=TRUE) # Creates a list of SpatialLines objects
      #}, 
      #error = function(e) {
      #  # Not sure why this happens. By putting stop() here it means I can debug this environment, 
      #  # not the ones lower-down (which aren't causing the problem)
      #  warning(e)
      #  stop()
      #}
      #) # tryCatch
  
    if (plot) {
      plot(cell,border='gray', add=T) # for debug
      #plot(lines.in.cell, add=T,col='red') # for debug
    }
    

    #print(paste("Cell:",cellid,"lines:",length(lines.in.cell)))
    #if (!is.null(lines.in.cell)) { # There are some lines in the cell - NOT NEEDED NOW, CHECKED EARLIER
    for (lineno in seq(1,length(lines.in.cell))) {
      # Check for things that aren't lines. Sometimes the intersection creates points, not lines. Not sure 
      # why but this might mess up the counting later.
      if ( class(lines.in.cell[[lineno]]) == "SpatialLines" ) { #
        
        # Note that if a line leaves and re-enters the cell then its SpatialLines object will have two discrete parts,
        # although it is stored as a single feature. This is pretty unusual but needs to be managed.
        # The next line handles this. It's horrible.
        #the.lines <- lines.in.cell[lineno,]@lines[[1]]@Lines # (Needed ',' before having to mess around with gIntersection)
  
        the.lines <- lines.in.cell[[lineno]]@lines[[1]]@Lines

        # Now go through each line and work out how it interacts with the cell 
        for (line in the.lines) {
          # Get the coords of the line https://stat.ethz.ch/pipermail/r-sig-geo/2009-July/006017.html
          # (old way before I notices that lines can leave and re-enter the cell)
          #line <- lines.in.cell[lineno]
          #coords.list <- lapply(slot(line, "lines"), function(x) lapply(slot(x, "Lines"), function(y) slot(y, "coords")))
          
          coords.list <- line@coords
          #print(coords.list)
          coords <- data.frame(coords.list)
          #plot(lines.in.cell[lineno],add=T,col='green') # for debug
          # Define start and end points and work out whether they're touching the cell boundary or not
          start <- SpatialPoints(coords[1,], proj4string = PROJ4STRING)
          end   <- SpatialPoints(coords[nrow(coords),], proj4string = PROJ4STRING)
          start.within <- gContains(cell, start) # Is the start point *inside* the cell? Has to be wholly inside,
          end.within   <- gContains(cell, end)   # not touching the border.
          
          # Work out which of the three conditions we have here (passing through, starting, ending)
          
          if (start.within & end.within) { # WHOLLY CONTAINED
            # If both start and end points are within the cell then the line is wholly contained within the cell
            wholly.contained <- wholly.contained + 1
            if (plot) {plot(cell,col='red', add=T)}
              
          } else if (start.within) { # BEGINS 
            # If the start point is within the cell then the line begins here
            # Work out which compass direction the cell is going to
            index.to <- find.nsew(cell,end) # This is a list with four booleans (N, S, E, W).
            stopifnot( length(index.to[index.to==TRUE]) == 1 ) 
            departure.count[c(index.to)]  <- departure.count[c(index.to)] + 1
            
            starting.count <- starting.count + 1 # For info (not used in making the transition matrix)
            if (plot) {plot(cell, col=rgb(0,1,0,0.5), add=T) }
            
          } else if (!start.within & !end.within) { # PASES THROUGH
            # If neither the start point nor end point are within the cell then the line passes through it.
            # Work out which compass direction the cell has come from and where it is going to  (N, E, S, W).
            index.to <- find.nsew(cell,end) # This is a list with four booleans (N, S, E, W).
            stopifnot( length(index.to[index.to==TRUE]) == 1 ) 
            departure.count[c(index.to)]  <- departure.count[c(index.to)] + 1
            
            if (plot) { plot(cell,border='blue', add=T)}
    
          } else if (end.within) { # ENDS
            # If the end point is within the cell then the line ends here
            ending.count <- ending.count + 1 # For info
            
            if (plot) { plot(cell, col=rgb(1,0,0,0.5), add=T) }
          }
          
          else {
            stop("Internal error - should not have got here.")
          }
        
        } # for linesegments
      
      } # if class(lines)==SpatialLines
      
    #}# for lines in cell

  } # if !is.null (the cell has lines)
  
  } # if intersecting > 0
  
  # Run the garbage collector occasionally. This might (?) help with the memory explosion that mclapply
  # causes (which is used to execute this function over all cells)
  if (run.gc & runif(1) < 0.2) gc()
 
  # Return the cell, and all the information about lines passing through it
  return(list(
    "cell"=cell,
    "departure.count"=departure.count,
    "starting.count"=starting.count,
    "ending.count"=ending.count,
    "wholly.contained"=wholly.contained,
    "total.intersection"=total.intersection)
  )
}


#' Iteratively call `calc.cell` to work out how many traces start, end, and pass through each cell
#' 
#' @param the.grid The grid to aggregate to 
#' @param the.traces The traces to analyse
#' @return A list with the information for each grid cell. See `calc.cell` for details about the 
#' information returned for each cell
#' @examples
#' result <- make.transition.matrix(grid,all.routes)
calc.flows <- function(the.grid, the.traces, plot=TRUE, multithread=TRUE) {
  
  if (plot) {
    plot(the.grid, border='black')
    polygonsLabel(the.grid, paste(the.grid$ID,'\n(',the.grid$CellX,',',the.grid$CellY,')', sep=""), cex=0.3 )
    lines(the.traces)
  }
  
  # First make a list of the individual cells 
  cells <- lapply(seq(1,length(the.grid)), FUN = function(i,g) { return(g[i,]) }, g=the.grid)
  
  # Now have each cell find out about the lines passing through it. 
  # This will return a list of cells and counts of relevant lines.
  results.cells <- 
    if (multithread) 
      mclapply(cells, FUN=calc.cell, the.traces=the.traces, plot=plot, run.gc=TRUE)
    else
      lapply(cells, FUN=calc.cell, the.traces=the.traces, plot=plot)
  
  return(results.cells)
  
} # function make.transition.matrix

#' Convert the output of calc.flows (a list) to a SpatialPolygonsDataFrame
#' 
#' @param result The results list from calc.flows
#' @examples
#' result.list <- calc.flows(grid,all.routes)
#' result.spdf <- result.to.spdf(result.list)
result.to.spdf <- function(result) {
  # Extract the polygons and their data from the list of results
  polys.polygons <- lapply(result, function(x){x$cell@polygons[[1]]}) #   https://gis.stackexchange.com/questions/180682/merge-a-list-of-spatial-polygon-objects-in-r

  polys.data <- data.frame(
    "ID" = unlist(lapply(result, function(x){x$cell$ID})),
    "CellX" = unlist(lapply(result, function(x){x$cell$CellX})),
    "CellY" = unlist(lapply(result, function(x){x$cell$CellY})),
    "departure.count.N" = unlist(lapply(result, function(x){x$departure.count[[1]]})),
    "departure.count.E" = unlist(lapply(result, function(x){x$departure.count[[2]]})),
    "departure.count.S" = unlist(lapply(result, function(x){x$departure.count[[3]]})),
    "departure.count.W" = unlist(lapply(result, function(x){x$departure.count[[4]]})),
    "starting.count" = unlist(lapply(result, function(x){x$starting.count})),
    "ending.count" = unlist(lapply(result, function(x){x$ending.count})),
    "wholly.contained" = unlist(lapply(result, function(x){x$wholly.contained})),
    "total.intersection"=unlist(lapply(result, function(x){x$total.intersection}))
  )

polys <- SpatialPolygonsDataFrame(
  SpatialPolygons(polys.polygons, proj4string=PROJ4STRING), 
  polys.data, match.ID = FALSE
  )

}

#' Convert the output of results.to.spdf (a SpatialPolygonsDataFrame with counts of the number
#' of traces departing from each cell) to a transition matrix.
#' 
#' @param spdf The SpatialPolygonsDataFrame (output from results.to.spdf)
#' @examples
#' result.list <- calc.flows(grid,all.routes)
#' result.spdf <- result.to.spdf(result.list)
#' result1.matrix <- spdf.to.matrix(result1.spdf)
spdf.to.matrix <- function(spdf) {
  # Define an empty matrix. Origins the columns and destinations are rows. This looks backwards because
  # matricies are accessed by m[row,col]
  trans.mat <- matrix(data=0, nrow=nrow(spdf), ncol=nrow(spdf))

  # Iterate over each cell and increment the relevant values
  for(i in seq(1,nrow(spdf))) {
    cell <- spdf[i,]
    x <- cell$CellX
    y <- cell$CellY
    oid <- cell$ID # origin id
    
    # Work out the destination ID (N, S, E, W) and then increment the appropriate cell matrix. Ignore the
    # posibility of lines departing out of the grid (i.e. border cases)
    
    if ( y > 0 ) { # N
      # (Can only have a line departing to the north if we're not in the first row)
      did.N <- grid.ids[y-1,x] # Destination ID to the north
      trans.mat[did.N,oid] <- trans.mat[did.N,oid] + cell$departure.count.N
    }
    if ( x < num.cells ) { # E
      did.E <- grid.ids[y,x+1] # Destination ID to the east
      trans.mat[did.E,oid] <- trans.mat[did.E,oid] + cell$departure.count.E
    }
    if ( y < num.cells ) { # S
      did.S <- grid.ids[y+1,x] # Destination ID to the south
      trans.mat[did.S,oid] <- trans.mat[did.S,oid] + cell$departure.count.S
    }
    if ( x > 0 ) { # W
      did.W <- grid.ids[y,x-1] # Destination ID to the west
      trans.mat[did.W,oid] <- trans.mat[did.W,oid] + cell$departure.count.W
    }
  }
  # Finally transpose the matrix, so that the origins are rows not colums (as in the Ratti paper)
  return(t(trans.mat))
}

```

### Make the matrix

Calculate the transition matrix! This will take some time, use loads of memory (especially if in multi-threaded mode) and heat up your computer. Good luck.

```{r makeMatrix}

# Calulate the flows into and out of cells. This makes a list with lots of information
result1 <- calc.flows(grid, all.routes, plot=FALSE, multithread = TRUE)

# Convert that list of results to a SpatialPolygonsDataFrame
result1.spdf <- result.to.spdf(result1) 

# Finally make a transition matrix 
result1.matrix <- spdf.to.matrix(result1.spdf)

# Write out the matrix
#write.csv(result1.matrix, file="/Users/nick/Desktop/result1.csv")
writeOGR(result1.spdf, dsn = "result", layer="result1_spdf", driver="ESRI Shapefile")

# Save the objects - easy to read back in
save(result1, result1.spdf, result1.matrix, num.cells, total.cells, file="results.RData")

```

_The code below is for testing the algorithm, it defines a few test routes and makes a small grid_

```{r makeTrasitionMatrixTest, eval=FALSE, echo=FALSE}

# Make a tiny grid for testing
num.cells <- 10
total.cells <- num.cells ** 2
cell.width <-  (71.07-71.05) / num.cells
cell.height <- (42.37-42.344) / num.cells
centre.x <- -71.07 + ( cell.width / 2 )
centre.y <- 42.344 + ( cell.height / 2 )
grd2 <- GridTopology(cellcentre.offset = c(centre.x, centre.y), cellsize = c(cell.width, cell.height), cells.dim = c(num.cells, num.cells) )
grid2 <- SpatialPolygonsDataFrame( as.SpatialPolygons.GridTopology(grd2), data = data.frame("ID"=rep.int(-1,total.cells),"CellX"=rep.int(-1,total.cells),"CellY"=rep.int(-1,total.cells)),match.ID = FALSE  )
rm(grd2)
proj4string(grid2) <- PROJ4STRING
# Set the ID properly
grid2.ids <- matrix(data=0, nrow=num.cells, ncol=num.cells)
cellcount <- 1
for (rowcount in seq(1,num.cells)) {
  for (colcount in seq(1,num.cells)) {
    grid2@data[cellcount,]$CellX <- colcount
    grid2@data[cellcount,]$CellY <- rowcount
    grid2@data[cellcount,]$ID <- cellcount
    grid2.ids[rowcount,colcount] <- cellcount
    cellcount <- cellcount + 1
  }
}

# Temporarily choose a few routes for testing
par(mfrow=c(1,1))
#plot(all.routes.oneline,axes=T,xlim=c(-71.07,-71.05), ylim=c(42.343,42.37), col='gray')
#plot(grid2, border='blue', axes=T)
#plot(all.routes.oneline,col='gray',add=T)
#plot(all.routes[2,],col='blue',add=T)
#plot(all.routes[4,],col='green',add=T)
#plot(all.routes[5,],col='orange',add=T)
#plot(grid2, border='blue', add=T)


# Plot the test grids and routes
plot(grid2, border='blue', main="Grid labels")
polygonsLabel(grid2, paste('(',grid2$CellX,',',grid2$CellY,')', sep=""), cex=0.4 )
test.routes <- rbind(all.routes[2,],all.routes[4,],all.routes[5,])
plot(test.routes, add=T)


# Test the algorithm
test.result <- calc.flows(grid2, test.routes, plot=TRUE, multithread = FALSE)
test.spdf <- result.to.spdf(test.result) 
test.matrix <- spdf.to.matrix(test.spdf)
#write.csv(test.matrix, file="/Users/nick/Desktop/test_matrix.csv")

```

### Comparing in- and out-flows for symmetry

As all flows in-to and out-of a cell involve an interaction with only one of the four possible von Neumann neighbours, we can test the symmetry of traces passing through each cell by calculating the flow in-to and out-of each cell as a 4-element vectors (_fin(i)_ and _fout(i)_ respectively). Then the _relative flow_ (_frel(i)_)can be defined as the magnitude difference between the _fin(i)_ and _fout(i)_ vectors. If all traces are symmetrical, then for all cells the number of traces entering the cell from each direction will be equal to the number of traces leaving from the same direction.

```{r relativeFlowSymmetry}

# Calculate the flows in-to and out-of each cell in each direction using the transition matrix

rel.flow <- c() # Relative flow in each cell (absoulte difference between fin and fout vetors for each cell)
total.flow <- c() # Useful for percentages

calc.flow <- function(o,d) { # Calculate flow from o to d, checking for boundary errors
    if ( o > total.cells || o < 1 || d > total.cells || d < 1) {
      return (0)
    } else {
      return(result1.matrix[o,d])
    }
}

# Iterate over all cells 
for (cell in seq(1, total.cells)) {
  
  # Work out which cell IDs make up the von Neuman neighbours of the curent cell. These are used to index into the transition matrix
  n <- cell - num.cells # (number of cells per row)
  e <- cell +1
  s <- cell + num.cells
  w <- cell -1
  
  # Flows into the cell from N E S W. Note that matrix is accessed by mat[y,x] (not x,y)
  fin <- c(
    calc.flow(n,cell), # N
    calc.flow(e,cell), # E
    calc.flow(s,cell), # S
    calc.flow(w,cell) # W
  )
  fout <- c(
    calc.flow(cell, n), # N
    calc.flow(cell, e), # E
    calc.flow(cell, s), # S
    calc.flow(cell, w) # W
  )
  # Relative flow is the Euclidean distance between inflows and outflows
  frel <- dist(rbind(fin, fout))
  rel.flow <- c(rel.flow, frel)
  
  # Also remember the total flow
  total.flow <- c(total.flow, result1[[cell]]$total.intersection)
  
}


```

Lets see the distribution of total and relative flows

```{r relativeFlowSymmetry-Distributions }


par(mfrow=c(1,2))
hist(rel.flow, breaks="Scott", main="Distribution of relative flows", xlab=expression("f"["rel"]*"()."))
hist(rel.flow/total.flow, breaks="Scott", main="Relative flow proportions", xlab=expression("f"["rel"]*"()/total_flow."))

# And one for the paper
pdf(file="relative_flow_symmetry-distributions.pdf", width = 7, height = 7)
par(mfrow=c(1,2))
hist(rel.flow, breaks="Scott", main="Distribution of relative flows", xlab=expression("f"["rel"]*"()."))
hist(rel.flow/total.flow, breaks="Scott", main="Relative flow proportions", xlab=expression("f"["rel"]*"()/total_flow."))
dev.off()



```

Map those relative flows

```{r relativeFlowSymmetry-Distributions, fig.width=11, fig.height=7}

# Attach the relative flows to the spatial data frame for mapping
result1.spdf@data$rel.flow <- rel.flow # Relative flow
result1.spdf@data$rel.flow.prop <- rel.flow/total.flow # proportion (catching zero division)
result1.spdf$rel.flow.prop[is.nan(result1.spdf$rel.flow.prop)] <- 0

par(mfrow=c(1,2))
choropleth(result1.spdf, result1.spdf@data$rel.flow, main="Relative flow asymmetry, frel()")
choropleth(result1.spdf, result1.spdf@data$rel.flow.prop,  main = "Proportions - frel()/total.flows")

```

_At this point write out the result1 data frame as a shapefile and make a map in ArcGIS_

### Within-cell flow

Compute incoming and outgoing flows for each cell and see if they're semetrical.

```{r withinCellFlows}

inflow <- colSums(result1.matrix)
outflow <- rowSums(result1.matrix)

# Make a linear model to quantify difference in flows (degree of symmetry)
within.cell.model <- lm(inflow~outflow)

par(mfrow=c(1,1))
plot(inflow,outflow, main="Within-Cell Flows", xlab="In Flow", ylab="Out Flow")
# abline(within.cell.model, col="red")
abline(a=0,b=1,col="gray", lty=3)
#legend("topright", legend=c("x=y","Model"), col=c("black","red"), lty=1 )
legend("topright", legend=c("x=y"), col=c("gray"), lty=3 )

# And one for the paper
pdf(file="within_cell_flow_correlation.pdf", width = 7, height = 7)
plot(inflow,outflow, main="Within-Cell Flows", xlab="In Flow", ylab="Out Flow")
abline(a=0,b=1,col="gray", lty=3)
legend("topright", legend=c("x=y"), col=c("gray"), lty=3 )
dev.off()


# The correlation
cor(inflow,outflow)

```

Whilst they're not symmetrical, they are very similar. The correlation is `r cor(inflow,outflow)`

The following shows the distribution of the flows:

```{r withinCellDistribution}

par(mfrow=c(2,2))
hist(inflow,  breaks="Scott")
hist(outflow, breaks="Scott")
plot(density(inflow))
plot(density(outflow))

```

### Pairwise flow

Now look at the flows between cells. The aim is to see whether the matrix is symmetrical, i.e. M=M^T^. Following the Ratti paper, constuct absolute and relative _difference matrix_.

```{r pairwiseFlows}

result1.abs.diff.matrix <- matrix(NA,nrow=nrow(result1.matrix),ncol=ncol(result1.matrix))
result1.rel.diff.matrix <- matrix(NA,nrow=nrow(result1.matrix),ncol=ncol(result1.matrix))


for ( i in seq(1,nrow(result1.matrix))) {
  for (j in seq(1, ncol(result1.matrix))) {
    if (i <= j) { # Don't need bottom half of the matrix, it will be identical to top half ('triangular')
      maximum <- max(result1.matrix[i,j],result1.matrix[j,i])
      # Absolute and relative difference (ignoring cells with no flows, where max=0, which will stay as NA)
      if (maximum > 0) {
        result1.abs.diff.matrix[i,j] = abs(result1.matrix[i,j] - result1.matrix[j,i])
        result1.rel.diff.matrix[i,j] = abs(result1.matrix[i,j] - result1.matrix[j,i]) / maximum
      }
    }
  }
}
# Sanity check: the number of non-zero items in each matrix should be the same
stopifnot(length(which(result1.abs.diff.matrix>0)) == length(which(result1.rel.diff.matrix>0)) )
# Also all relative flows should be in range [0,1]
stopifnot(length(result1.rel.diff.matrix[which(result1.rel.diff.matrix<0 | result1.rel.diff.matrix>1)]) == 0)

#write.csv(result1.abs.diff.matrix, file="/Users/nick/Desktop/result1_abs_diff.csv")
#write.csv(result1.rel.diff.matrix, file="/Users/nick/Desktop/result1_rel_diff.csv")

```

There are `r length(which(result1.abs.diff.matrix>0))` non-zero flows. Note: in the results matrices, NA indicates no flow between i,j, whereas 0 represents no _difference_ in the flow.

Summary information: 

 - Absolute flows: `r summary(result1.abs.diff.matrix[which(result1.abs.diff.matrix>0)])`
 - Relative flows: `r summary(result1.rel.diff.matrix[which(result1.rel.diff.matrix>0)])`

Now calculate the _percentage of of asymmetry_

```{r pairwiseFlow-percentage_asymmetry}

sum.absolute.flow <- 0
sum.max.flow <- 0
  
for ( i in seq(1,nrow(result1.matrix))) {
  for (j in seq(1, ncol(result1.matrix))) {
    if (i < j) { # Discard bottom half of matrix *and* don't include where i==j
      sum.absolute.flow <- sum.absolute.flow + abs(result1.matrix[i,j] - result1.matrix[j,i])
      sum.max.flow <- sum.max.flow + max(result1.matrix[i,j], result1.matrix[j,i] )
    }
  }
}
percentage.asymmetry <- sum.absolute.flow / sum.max.flow
```

The percentage asymmetry is `r round(percentage.asymmetry,5) * 100`%. Therefore asymmetric flows account for `r round(percentage.asymmetry,2) * 100`% of all flows, or people change their routes `r round(percentage.asymmetry,2) * 100`% of the time.

### Map(s) of Asymmetric Flows

First map the number of traces that pass through each cell. For the final paper I atually do this in ArcMap.

```{r mapTracesPerCell, fig.width=15}

shades <- auto.shading(result1.spdf$total.intersection, n=9, cutter=quantileCuts)
choropleth(result1.spdf, result1.spdf$total.intersection, shading = shades)
choro.legend("topleft", sh=shades)
plot(all.routes.oneline, add=T, col=rgb(0.5,0.5,0.5,0.5))

```

XXXX maybe do these, will write up paper first.

