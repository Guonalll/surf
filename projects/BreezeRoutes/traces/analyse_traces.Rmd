---
title: "Analyse Traces"
author: "Nick Malleson"
date: "13 July 2016"
output:
  html_document: 
    toc: yes
    pandoc_args: [
      "+RTS", "-K64m",
      "-RTS"
    ]
  pdf_document:
    fig_crop: no
    highlight: kate
    keep_tex: yes
    latex_engine: xelatex
    number_sections: yes
fontsize: 10pt
---

An extension to the [map_traces.Rmd](./map_traces.Rmd) program. This has the facility to map traces, but focusses on analysing the difference between matched paths and their equivalent shortest path.

The three different kinds of routes that the script reads are:

 - original traces (the original GPX data)
 - matched routes (the original data matched to OSM routes)
 - shortest paths (the shortest paths the could be used to do the same route)

```{r initialise, echo=FALSE, message=FALSE, warning=FALSE}
library(knitr)
knitr::opts_knit$set(root.dir = "/Users/nick/mapping/projects/runkeeper/mitmount/runkeeper/mapmatching-traces/")
setwd("/Users/nick/mapping/projects/runkeeper/mitmount/runkeeper/mapmatching-traces/")
#setwd('~/research_not_syncd/git_projects/surf/projects/BreezeRoutes/traces')

# The binary file that contains all the traces (exhaustively read in on the server)
TRACES_FILE = "./traces-server-all.RData"
#TRACES_FILE = "./traces-temp.RData"

# Paths to the original files, shortest paths, and matched paths
path.org =      "./gpx/"
path.matched =  "./gpx-matched/"
path.shortest = "./gpx-shortest/"

library(GISTools)
#library(rgeos)    # For things like gIntersects
library(rgdal)     # For reading shapefiles
#library(raster)    # For creating regular grids or converting from SpatialPixelsDataFrame to raster
#library(plyr)     # For counting and aggregating
#library(tmap)     # For thematic maps
#library(classInt) # Jenks natural breaks
#library(png)      # For loading pngs after they have been written
#library(grid)     # so that they can be embedded in knitted documents
#library(spdep)    # For doing the spatial regression, contiguity matrices, etc.
#library(GWmodel)  # For geographically weighted regression (GWR)
#library(MASS)     # For stepwise regression (stepAIC())
#library(pander)   # For printing tables nicely
#library(MVN)      # For testing for multivariate normality (MVN)
#library(stats)     # For a-spatial aggregatiion (aggregate)
#library(ggplot2)   # For density scatter plot

#library(hexbin)    # For hexagonal density scatter plots in ggplot
#library(gridExtra) # To put two graphs next to each other in ggplot
library(plotKML)   # For reading GPX files
library(OpenStreetMap) # For plotting OSM basemaps
Sys.setenv(MC_CORES=4) # Run on n cores (I'm not sure which of these
options("mc.cores"=4L) # is correct).
library(parallel) # For ruonning things in parallel (e.g. mclapply())
library(plotKML)   # For reading GPX files
library(data.table) # For adding up distances per user (data.table())
```


# Function to map a trace

It is sometimes useful to visualise a particualr trace. This has come from [map_traces.Rmd](./map_traces.Rmd) - see that file for proper documentation.

```{r map.trace.function }

expanded.bb <- function(bounds) {
  
  bb <- bbox(bounds)
  # Make the bounding box x % larger to make sure none of the map is clipped
  width = bb[1,2] - bb[1,1]
  height = bb[2,2] - bb[2,1]
  x <- 0.10 # 20 % larger in total
  bb[1,1] = bb[1,1] - (width*x)
  bb[1,2] = bb[1,2] + (width*x)
  bb[2,1] = bb[2,1] - (height*x)
  bb[2,2] = bb[2,2] + (height*x)
  return(bb)
}

# A convenience for plotting a trace given a filename relative to cwd
map.file <- function(filename) {
  print(paste("Mapping GPX file",filename))
  # Create SpatialLinesDataFrames for the track
  track <- readOGR(dsn=filename, layer="tracks", verbose=FALSE )  
  # Project to WGS 84 / Pseudo Mercator (epsg:3857) for OSM
  track.merc <- spTransform(track, CRS("+init=epsg:3857"))
  
  bb <- expanded.bb(track@bbox)

  # Get an OSM basemap (coordinates are upper-left and lower-right)
  basemap <- openmap(
    upperLeft = c(bb[2,2],bb[1,1]), # Upper-left (lat,lon) (y,x)
    lowerRight = c(bb[2,1], bb[1,2]), # Lower-right
    type='osm', zoom=17)
  
  par(mfrow=c(1,1))
  plot(basemap)
  plot(track.merc, col='blue', lwd=3)
  title(paste("Track for\n",f), cex=0.5 )
}

# A convenience to call the plotting function defined below (just pass in the list index for the routes)
map.index <- function(N, osm=TRUE) {
  map.trace(orig[[N]], matched[[N]], shortest[[N]], osm=osm)
}

map.trace <- function(orig, matched, short, osm=TRUE) {
  # Get a bounding box for the whole dataset to make sure plots are big enough
  # Need to do this before projecting otherwise openmap() doesn't work (not sure why)
  bb <- expanded.bb(orig@bbox)
  
  # Project to WGS 84 / Pseudo Mercator (epsg:3857) for OSM
  matched.merc <- spTransform(matched, CRS("+init=epsg:3857"))
  orig.merc    <-   spTransform(orig,    CRS("+init=epsg:3857"))
  short.merc <- spTransform(short,    CRS("+init=epsg:3857"))
  
  # Get an OSM basemap (coordinates are upper-left and lower-right)
  if (osm) {
    basemap <- openmap(
      upperLeft = c(bb[2,2],bb[1,1]), # Upper-left (lat,lon) (y,x)
      lowerRight = c(bb[2,1], bb[1,2]), # Lower-right
      type='osm', zoom=17)
  }
  
  par(mfrow=c(1,1))
  if (osm) {
    plot(basemap)
  }
  else {
    plot(orig.merc, col='blue', lwd=3)
  }
  #title(paste("Routes for route",N), cex=0.5 )
  plot(orig.merc, col='blue', lwd=3, add=T)
  plot(matched.merc, lwd=3, col='black', add=T)
  plot(short.merc, col='green', lwd=3, add=T)
  
}

# Get the USER ID from an original gpx file
read.userid <- function(filename) {
  text <- tryCatch( 
    { readLines(filename) },
    error=function(cond) {
      message(paste("Could not read file for username: ", filename, '. Message is:', cond))
      return(-1)
    }
  ) # tryCatch
  if (text==-1) {
    return(-1)
  }
  result <- grep('userId=[A-z0-9]+', text, value=TRUE) # Find the bit with the User ID
  if (length(result)==0) {
    warning(paste("No match for user im file",filename))
    return (-1)
  }
  # Match looks ok, return the userid part.
  uid <- substring(result,8)
  #print(paste("Got UID: ",uid))
  return(uid)
}
  
```

# Read the Data

Read all of the traces and store in memory. Only read 'matched' traces because those will definitely have an original trace and a shortest path. Not all original traces have been matched by the MapMatcher program.


```{r readTraces}

if (!file.exists(TRACES_FILE)) {
  # Vectors that will contain all of the paths and associated information.
  orig <- list() 
  matched <- list()
  shortest <- list()
  orig.ma <- list()  # Projected versions
  matched.ma <- list()
  shortest.ma <- list()
  userid <- list()

  # Read files in the 'matched' directory. We're only interested in mapping routes that have been matched 
  # (and if they've ben matched then they probably also have a companion shortest path).
  file.names <- dir(path.matched, pattern =".gpx")
 
  for(i in 1:1000){
  #for(i in seq(length(file.names))){
    start.time <- proc.time()[['elapsed']]
    f <- substr(file.names[i], 1, nchar(file.names[i])-12) # The name of the file without the '-matched.gpx' extension.
    f.orig <-    paste(path.org,      f, ".gpx", sep="")
    f.matched <- paste(path.matched,  f, "-matched.gpx", sep="") # The matched file (f531b5395-matched.gpx)
    f.shortest<- paste(path.shortest, f, "-shortest.gpx", sep="") # The shortest path (f531b5395-shortest.gpx)
    print(paste("Reading file (",i,")",f))
    
    # Create SpatialLinesDataFrames for each track, project them to good projection for MA (Albers) add them to the lists
    # (https://www.arcgis.com/home/item.html?id=d075ba0b6b5e4d71b596e882493f7789)
    # Read the three required files simultaneously in parallel
    read.data <- mclapply(
      list("orig"=f.orig, "matched"=f.matched, "shortest"=f.shortest), 
      FUN=function(x){
        # Read the GPX and convert the $tracks to a dataframe. All wrapped in a try-catch in case file can't be read
        gpx <- as.data.frame(
          tryCatch(
            {
              readGPX(x, metadata = TRUE, bounds = TRUE,waypoints = FALSE, tracks = TRUE, routes = FALSE)$tracks
            },
            error=function(cond) {
              message(paste("Could not read file: ", x, '. Message is:', cond))
              return(NULL)
            },
            warning=function(cond) {
              message(paste("Could not read file: ", x, '. Message is:', cond))
              return(NULL)
            }
          ) #trycatch
        ) #as.data.frame
        # Work out where x,y coords are
        if ('GraphHopper.lon' %in% colnames(gpx) ) {
          xcor <- gpx$GraphHopper.lon
          ycor <- gpx$GraphHopper.lat
        } else {
          xcor <- gpx$lon
          ycor <- gpx$lat
        }
        
        lines <- SpatialLines(
          list(Lines(lapply(list(cbind(xcor, ycor)), Line), ID="a")),
          proj4string = CRS("+init=epsg:4326"))
        return(lines)
      }
    )
    orig[[i]]    =  read.data[['orig']]
    matched[[i]] =  read.data[['matched']]
    shortest[[i]] = read.data[['shortest']]
    
    transformed <- mclapply(
      list("orig.ma"=orig[[i]], "matched.ma"=matched[[i]], "shortest.ma"=shortest[[i]]),
      FUN = function(x) { return(spTransform(x, CRS("+init=epsg:5070")) ) }
    )
    orig.ma[[i]] =    transformed[['orig.ma']]
    matched.ma[[i]] = transformed[['matched.ma']]
    shortest.ma[[i]] =transformed[['shortest.ma']]
   
    # To get the user id we need to re-read the original gpx file and parse it manually. The
    # readGPX function doesn't keep the meta-data, and readOGR is too slow.
    uid <- read.userid(f.orig)
    if (uid == -1) {
      warning(paste("Not able to get the user ID for route (",i,")", f ) )
      uid = "NA"
    }
    userid[[i]] = uid
    
    # OLD WAY OF GETTING UID WHEN SING readOGR
    ## Get the user ID. This needs to be done by parsing the description as readOGR didn't bring in the metadata properly)
    ## Split the string on '\n' (fixed=T means treat this as it is, not as a regex), and take the 6th element
    ##which should be a string like: userId=857ac8242e49159c7abb25bb458a7bc9. Then just get the id from that
    #uid_str <- strsplit(as.character(orig[[i]]@data$desc), '\n', fixed=T)[[1]][6] 
    #uid_split <- strsplit(uid_str, '=')[[1]]
    #uid = uid_split[2] # Second element after splitting on '='
    #if (uid_split[1]!="userId") {
    #  warning(paste("Not able to get the user ID for route (",i,")", f ) )
    #  uid = "NA"
    #}
    #userid[[i]] = uid
    
    print(paste("\t.. finished in",round(proc.time()[['elapsed']]-start.time,digits=2),"secs"))
    
  }# for files
    
  
  if (length(matched) != length(orig) || length(matched) != length(shortest) || length(matched) != length(userid)) {
    warning("For some reason there are different numbers of original, matched, and shortest paths.")
  }
  
  # Save the traces
  save(orig, matched, shortest, orig.ma, matched.ma, shortest.ma, userid, file=TRACES_FILE)

} else {
  print(paste("Loading traces from file", TRACES_FILE))
  load(TRACES_FILE)
}

```

Read `r length(matched)` matched traces, `r length(orig)` original traces, and `r length(shortest)` shortest paths.

# Filter Bad Matches

Earlier in the data anlysis process, clean traces were filtered out (see `2-breeze-analyse_data.Rmd`). This removed traces that, e.g. were too short to be useful. Now clean out traces that have not been matched to a given accuracy threshold (i.e. the shortest and matched traces are substantially different.)

Need to decide what 'outliers' are. Try the mean+1sd (red lines) and Q3+1.5*IQR (blue lines).

```{r findBadMatchedPaths, fig.height=20 }

# Calculate the lenths of the paths
orig.lengths    <-  unlist(mclapply(orig.ma, FUN=gLength))
matched.lengths  <- unlist(mclapply(matched.ma, FUN=gLength))
shortest.lengths <- unlist(mclapply(shortest.ma, FUN=gLength))

# Calclulate the path differences between shortest and matched
abs.diff <- mcmapply( # Absolute distance
  FUN=function(a,b) {return(abs(a-b))},
  orig.lengths, matched.lengths
)
rel.diff <- mcmapply( # Absolute relative (percentage) difference
  FUN=function(a,b) {return(abs(100*(a-b)/a))},
  orig.lengths, matched.lengths
)
diff <- mcmapply( # Difference
  FUN=function(a,b) {return(a-b)},
  orig.lengths, matched.lengths
)

summary(diff)
summary(abs.diff)
summary(rel.diff)


par(mfrow=c(5,2))
boxplot(diff, main="Difference between matched\nand original paths) (m)")
boxplot(diff, main="(short axxis)", ylim = c(-500,400))
boxplot(abs.diff, main="Abslute Difference (m)")
boxplot(abs.diff, main="(short axxis)", ylim = c(0,1000))
boxplot(rel.diff, main="Abslute Relative (percentage) Difference (m)")
boxplot(rel.diff, main="(short axxis)", ylim = c(0,200))

hist(abs.diff, breaks="Scott", main="Histogram of absolute difference", xlab="Difference (m)")
abline(v=mean(abs.diff)+1*sd(abs.diff), col="red")
abline(v=quantile(abs.diff)[4]+(1.5*IQR(abs.diff)), col="blue")

hist(abs.diff, breaks="Scott", xlim=c(0,3000), main="(short axis)")
abline(v=mean(abs.diff)+1*sd(abs.diff), col="red")
abline(v=quantile(abs.diff)[4]+(1.5*IQR(abs.diff)), col="blue")

hist(rel.diff, breaks="Scott", main="Histogram of relative difference", xlab="Percentage Difference (m)")
abline(v=mean(rel.diff)+1*sd(rel.diff), col="red")
abline(v=quantile(rel.diff)[4]+(1.5*IQR(rel.diff)), col="blue")

hist(rel.diff, breaks="Scott", xlim=c(0,200), main="(short axis)", xlab="Percentage Difference (m)")
abline(v=mean(rel.diff)+1*sd(rel.diff), col="red")
abline(v=quantile(rel.diff)[4]+(1.5*IQR(rel.diff)), col="blue")

```

It looks like the mean is pulled a lot by very severe outliers in the top end -- one trace has a difference between the original and the matched of `r max(abs.diff)`m! There are only `r length(which( abs.diff>(mean(abs.diff)+2*sd(abs.diff)) | rel.diff>(mean(rel.diff)+2*sd(rel.diff))))` traces that would be removed using the mean as the definition as an outlier, but `r length(which(abs.diff>(quantile(abs.diff)[4]+(1.5*IQR(abs.diff)))|rel.diff>(quantile(rel.diff)[4]+(1.5*IQR(rel.diff)))))` that would be removed using the quartile definition. This is quite a lot (too many) but will do for now.


```{r filterBadMatchedPaths}

#bad.indices <- which( abs.diff>(mean(abs.diff)+2*sd(abs.diff)) | rel.diff>(mean(rel.diff)+2*sd(rel.diff)))
bad.indices <- which( 
  abs.diff>(quantile(abs.diff)[4]+(1.5*IQR(abs.diff))) | 
  rel.diff>(quantile(rel.diff)[4]+(1.5*IQR(rel.diff)))
  )

orig <- orig[-bad.indices]
matched <- matched[-bad.indices]
shortest <- shortest[-bad.indices]
orig.ma <- orig.ma[-bad.indices]
matched.ma <- matched.ma[-bad.indices]
shortest.ma <- shortest.ma[-bad.indices]
userid <- userid[-bad.indices]

```

After filtering, there are `r length(matched)` matched traces, `r length(orig)` original traces, and `r length(shortest)` shortest paths.


# Compare path distances

## Actual paths v.s. shortest path

Look at the differences in the lengths between actual (matched) paths and shortest paths. The matched and original are very similar, and the shortest are shorter :-).

```{r compareLengthsHist1 }
# Need to recalculate lengths after filtering
orig.lengths    <-  unlist(mclapply(orig.ma, FUN=gLength))
matched.lengths  <- unlist(mclapply(matched.ma, FUN=gLength))
shortest.lengths <- unlist(mclapply(shortest.ma, FUN=gLength))

par(mfrow=c(1,3))
ylim <- c(0,10000)
xlim <- c(0,8000)

hist(orig.lengths,     breaks='Scott', xlim=xlim, ylim=ylim )
hist(matched.lengths,  breaks='Scott', xlim=xlim, ylim=ylim )
hist(shortest.lengths, breaks='Scott', xlim=xlim, ylim=ylim )
```

```{r compareLengthsHist2 }
par(mfrow=c(1,1))
d <- density(shortest.lengths, kernel="gaussian") # Remember first density plot so parameters can be reused
plot(d, col="blue", main="Trip distance distribution")

lines(density(orig.lengths, kernel="gaussian", bw=d$bw), col="grey")
lines(density(matched.lengths, kernel="gaussian", bw=d$bw), col="black")
legend("topright", c('Shortest', 'Original', 'Matched'), col=c('blue', 'grey', 'black'),lty=1)

```

```{r compareLengthsBoxPlot}
par(mfrow=c(1,1))
boxplot(list("Original"=orig.lengths,"Matched"=matched.lengths,"Shortest"=shortest.lengths),ylim=c(0,5000), main="Path distances (short y axis)", ylab="Path distance")
```

## Hausdorff distances

Look at the Hausdorff distances between the paths. This quantifies how similar the paths are.

```{r hausdorffDistancesHist1} 
# Run using lapply as above. This is just slightly more complicated because the distance function requires two 
# arguments as it compares two lines. mapply does this. The function comes first, followed by the arguments 
haus.orig.matched <- unlist(
  mcmapply(
    FUN=gDistance, # Function to calcuate the distance
    orig.ma, matched.ma, # First two arguments
    MoreArgs=list(byid=FALSE, hausdorff=TRUE) # Some other named argments
  )
)
haus.matched.shortest <- unlist(
  mcmapply(
    FUN=gDistance, # Function to calcuate the distance
    matched.ma, shortest.ma, # First two arguments
    MoreArgs=list(byid=FALSE, hausdorff=TRUE) # Some other named argments
  )
)
par(mfrow=c(1,2))
xlim=c(0,1000)
ylim=c(0,10000)
hist(haus.orig.matched, main="Hausdorff distance\nOriginal v.s. Matched", xlab="Distance", breaks="Scott",xlim=xlim,ylim=ylim)
hist(haus.matched.shortest, main="Hausdorff distance\nMatched v.s. Shortest", xlab="Distance",  breaks="Scott",xlim=xlim,ylim=ylim)

```

```{r hausdorffDistancesHist2} 
par(mfrow=c(1,1))
d <- density(haus.orig.matched, kernel="gaussian")
plot(d, main="Hausdorff distance distribution", col="grey", xlim=c(0,2000))
lines(density(haus.matched.shortest, kernel="gaussian", bw=d$bw), col="black")
legend("topright", c('Matched - Original','Matched - Shortest'), lty=1, col=c('grey','black'))

```

```{r hausdorffDistances2} 
par(mfrow=c(1,1))
boxplot(list("Matched<->Original"=haus.orig.matched, "Matched<->Shortest"=haus.matched.shortest), main="Hausdorff Distances (short y axis)",ylim=c(0,1000))

```

# Explore User distances

Look at the range of distances travelled by individual users. Is there some regularity?

First the number of traces per user.

```{r userDistances}
# Improved histogram for integers (https://mikelove.wordpress.com/2011/03/30/r-one-liner-histogram-for-integers/)
int.hist = function(x,ylab="Frequency",...) {
  barplot(table(factor(x,levels=min(x):max(x))),space=0,xaxt="n",ylab=ylab,...);axis(1)
}

# First find the frequency distribution of trips per user

uid.freq = as.data.frame(table(as.factor(unlist(userid))))
int.hist(uid.freq$Freq, main="Traces per user", xlab="Number of traces", ylab="Frequency (number of users)")
```

Now look at the distributions of mean and standard deviations

```{r userDistancesDist}

# A list of users and their total distances. Uses data.table. https://stackoverflow.com/questions/11782030/sum-by-distinct-column-value-in-r
uid.total.dists <- data.table(
  "userid"=unlist(userid), 
  "orig.lengths"=unlist(orig.lengths), 
  "matched.lengths"=unlist(matched.lengths), 
  "shortest.lengths"=unlist(shortest.lengths), 
  key="userid")
# Now sum that data table
uid.total.dists <- uid.total.dists[,list(sum(orig.lengths), sum(matched.lengths), sum(shortest.lengths), (.N) ), by=userid]
names(uid.total.dists) <- c("userid", "orig", "matched", "shortest", "N")

par(mfrow=c(1,2))
boxplot(list(
  "Orig"=uid.total.dists$orig/uid.total.dists$N, 
  "Shortest"=uid.total.dists$matched/uid.total.dists$N,
  "Matched"=uid.total.dists$matched/uid.total.dists$N),
  main="Average distances\ntravelled per user (m)",
  ylab="Mean distance travelled (m)")
boxplot(list(
  "Orig"=uid.total.dists$orig/uid.total.dists$N, 
  "Shortest"=uid.total.dists$matched/uid.total.dists$N,
  "Matched"=uid.total.dists$matched/uid.total.dists$N),
  main="(short y axis)",
  ylim=c(0,3000))

```

# Quantify Symmetry

Replicate the work in Phithakkitnukoon and Ratti (2011):

Phithakkitnukoon, Santi, and Carlo Ratti (2011). Inferring Asymmetry of Inhabitant Flow Using Call Detail Records. _Journal of Advances in Information Technology_ 2(4). http://ojs.academypublisher.com/index.php/jait/article/view/jait0204239249.

## Process:

  - Split area into grid cells
  - Calculate transition matrix, M, (shows flows between cells)
  - Calculate in- and out-flows for cells. Symmetrical?
  - Calculate symmetry of M
  - Look at places that are not symmetrical.
  
**For the similarity analysis only work with the matched traces**
  
## Define study area

Need to define the study area.

Begin by creating single SpatialLines objects from the discrete Lines (traces).

```{r createSingleLine}
# Use a consistent projection
PROJ4STRING <- matched[[1]]@proj4string

# Begin by creating a single SpatialLines object of all matched lines (https://stackoverflow.com/questions/18023462/how-to-unlist-spatial-objects-and-plot-altogether-in-r)

#  Get the Lines objects which contain multiple 'lines'
lines.objects <- unlist( mclapply( matched , function(x) `@`(x , "lines") ) )
# Give each an ID based on its index
for (i in seq(1,length(matched))) { lines.objects[[i]]@ID <- as.character(i) }

# Make a SpatialLines object from all of those lines
all.routes <- SpatialLines(lines.objects, proj4string = PROJ4STRING)

#  Also make one bg SpatialLies object for mapping. Begin by extracting the individual 'lines'
individual.lines <- mclapply( lines.objects , function(y) `@`(y,"Lines") )
#  Combine them into a single SpatialLines object. This is good for quick plotting etc.
all.routes.oneline <- SpatialLines( list( Lines( unlist( individual.lines ) , ID = 1 ) ), proj4string = PROJ4STRING )

plot(all.routes.oneline, axes=T, main="All Traces")

# Useful to analyse in a GIS
writeOGR(SpatialLinesDataFrame(all.routes.oneline, data=data.frame(1)), dsn=".", layer="all_routes.shp",driver="ESRI Shapefile", overwrite_layer=TRUE)

```

Now define the study are (fairly arbitrary)

```{r defineStudyArea}

# Define the study area (farily arbitrary)
study.area.bb <- all.routes.oneline@bbox
study.area.bb[1,1] <- -71.2 # x min
study.area.bb[1,2] <- -71.0 # x max
study.area.bb[2,1] <-  42.26 # y min
study.area.bb[2,2] <-  42.42  # y max
#study.area.bb[1,1] <- -7920375 # x min
#study.area.bb[1,2] <- -7908295 # x max
#study.area.bb[2,1] <-  5206223 # y min
#study.area.bb[2,2] <-  5221410 # y max

study.area.coords <- rbind(
  cbind(study.area.bb[1,1],study.area.bb[2,1]),
  cbind(study.area.bb[1,1],study.area.bb[2,2]),
  cbind(study.area.bb[1,2],study.area.bb[2,2]),
  cbind(study.area.bb[1,2],study.area.bb[2,1])
)

# Make a polygon from the bounding box
study.area <- SpatialPolygons(list(Polygons(list(Polygon(study.area.coords)), ID = "b")), proj4string = PROJ4STRING)

par(mfrow=c(1,1))
plot(all.routes.oneline, axes=T, main="All Traces and the Study Area")
points(study.area.coords, col="red")
plot(study.area, col=rgb(1, 0, 0,0.3), add=T)

```

## Make the grid (will become the transition matrix)

Now create a regular grid that covers the study area. This will be used to create the transition matrix

```{r makeGridForTransitionMatrix, fig.width=15}

# The number of cells per row or column
num.cells <- 10
total.cells <- num.cells ** 2

# Create the grids - adapted from Brunsdon & Comber (2015, p150)
cell.width <-  (study.area.bb[1,2] - study.area.bb[1,1]) / num.cells
cell.height <- (study.area.bb[2,2] - study.area.bb[2,1]) / num.cells

#cell.areas <- c(cell.areas, (cell.width * cell.height) ) # Also remember the cell area for later

centre.x <- study.area.bb[1,1] + ( cell.width / 2 )
centre.y <- study.area.bb[2,1] + ( cell.height / 2 )

# Make the grid
grd <- GridTopology(
  cellcentre.offset = c(centre.x, centre.y), # No offset, the grid will just cover all the points
  cellsize = c(cell.width, cell.height),
  cells.dim = c(num.cells, num.cells)
  )

# Convert it into a polygons data frame, and give each cell it's x and y locations in the matrix (-1 initially)
grid <- SpatialPolygonsDataFrame(
  as.SpatialPolygons.GridTopology(grd),
  data = data.frame("CellX"=rep.int(-1,total.cells),"CellY"=rep.int(-1,total.cells)),
  match.ID = FALSE
  )
proj4string(grid) <- PROJ4STRING
#names(grid) <- "CellID" # Name the ID column
# Set the ID properly
cellcount <- 1
for (rowcount in seq(1,num.cells)) {
  for (colcount in seq(1,num.cells)) {
    grid@data[cellcount,]$CellX <- rowcount
    grid@data[cellcount,]$CellY <- colcount
    cellcount <- cellcount + 1
  }
}

par(mfrow=c(1,2))
plot(grid, border='blue', main="Routes and the grid")
plot(all.routes.oneline, add=T)

plot(grid, border='blue', main="Grid labels")
polygonsLabel(grid, paste('(',grid$CellX,',',grid$CellY,')', sep=""), cex=0.4 )

```

## Calculate transition matrix, M

Process:

 1. Iterate over each cell
    1. Clip the traces within the cell
    1. Iterate over each (sub) trace
      - Identify one of three possible conditions

      1. The line passes through the cell
         - Increment the _departure_ count for the cell that the line _came from_
         - Increment the _arrival_ count for the cell that the line is _going to_
      1. The line begins in the cell
         - Increment the _arrival_ count for the cell that the line is _going to_
      1. The line ends in the cell
         - Increment the _departure_ count for the cell that the line _came from_
      1. The line is wholly contained within the cell
         - XXXX WHAT DO DO?! Check Ratti paper

_The code below is for testing the aggorithm_

```{r makeTrasitionMatrixTest, eval=FALSE}


# Make a tiny grid for testing
num.cells <- 10
total.cells <- num.cells ** 2
cell.width <-  (71.07-71.05) / num.cells
cell.height <- (42.37-42.344) / num.cells
centre.x <- -71.07 + ( cell.width / 2 )
centre.y <- 42.344 + ( cell.height / 2 )
grd2 <- GridTopology(cellcentre.offset = c(centre.x, centre.y), cellsize = c(cell.width, cell.height), cells.dim = c(num.cells, num.cells) )
grid2 <- SpatialPolygonsDataFrame( as.SpatialPolygons.GridTopology(grd2), data = data.frame("CellX"=rep.int(-1,total.cells),"CellY"=rep.int(-1,total.cells)),match.ID = FALSE  )
proj4string(grid2) <- PROJ4STRING
# Set the ID properly
cellcount <- 1
for (rowcount in seq(1,num.cells)) {
  for (colcount in seq(1,num.cells)) {
    grid2@data[cellcount,]$CellX <- rowcount
    grid2@data[cellcount,]$CellY <- colcount
    cellcount <- cellcount + 1
  }
}

# Temporarily choose a few routes for testing
par(mfrow=c(1,1))
#plot(all.routes.oneline,axes=T,xlim=c(-71.07,-71.05), ylim=c(42.343,42.37), col='gray')
plot(grid2, border='blue', axes=T)
plot(all.routes.oneline,col='gray',add=T)
plot(all.routes[2,],col='blue',add=T)
plot(all.routes[4,],col='green',add=T)
plot(all.routes[5,],col='orange',add=T)
plot(grid2, border='blue', add=T)


plot(grid2, border='blue', main="Grid labels")
polygonsLabel(grid2, paste('(',grid2$CellX,',',grid2$CellY,')', sep=""), cex=0.4 )


#test.routes <- rbind(all.routes[2,],all.routes[4,],all.routes[5,])
#plot(test.routes)
#plot(grid2, add=T)


```

```{r doIT}

# This function does most of the work. It takes a cell (a SpatialPolygonsDataFrame), calculates whether
# it has lines passing through it, and returns the cell with this information in a list
f <- function(cell, the.traces, plot=TRUE) {
  
  # Remember the number of lines entering and leaving the cell, and their direction.
  # Store for values for each one, representing whether the line has crossed the n,s,e, or w boundary
  came.from <- c(0,0,0,0) # A line entered this cell
  going.to <- c(0,0,0,0) # A line is leaving this cell
  
  # Also useful to remember the number of lines starting and finishing here. Don't need direction with 
  # these though as this is captured in the vectors above
  starting.count <- 0
  ending.count   <- 0
  wholly.contained <- 0 # The line starts and ends in the cell without going through another cell.
  

  # Clip the lines in this cell
  #cell<- the.grid[cellid,]
  lines.in.cell <- gIntersection(cell,the.traces, byid=TRUE) # Creates a list of SpatialLines objects
  
  if (plot) {
    plot(cell,border='gray', add=T) # for debug
    #plot(lines.in.cell, add=T,col='red') # for debug
  }
  
  #print(paste("Cell:",cellid,"lines:",length(lines.in.cell)))
  if (!is.null(lines.in.cell)) { # There are some lines in the cell
    for (lineno in seq(1,length(lines.in.cell))) {
      # Note that if a line leaves and re-enters the cell then its SpatialLines object will have two discrete parts,
      # although it is stored as a single feature. This is pretty unusual but needs to be managed.
      # The next line handles this. It's horrible but works.
      for (line in lines.in.cell[lineno,]@lines[[1]]@Lines) {
        #print(paste("\tline:", lineno))
        # Get the coords of the line https://stat.ethz.ch/pipermail/r-sig-geo/2009-July/006017.html
        # (old way before I notices that lines can leave and re-enter the cell)
        #line <- lines.in.cell[lineno]
        #coords.list <- lapply(slot(line, "lines"), function(x) lapply(slot(x, "Lines"), function(y) slot(y, "coords")))
        coords.list <- line@coords
        #print(coords.list)
        coords <- data.frame(coords.list)
        #plot(lines.in.cell[lineno],add=T,col='green') # for debug
        # Define start and end points and work out whether they're touching the cell boundary or not
        start <- SpatialPoints(coords[1,], proj4string = PROJ4STRING)
        end   <- SpatialPoints(coords[nrow(coords),], proj4string = PROJ4STRING)
        start.within <- gContains(cell, start) # Is the start point *inside* the cell? Has to be wholly inside,
        end.within   <- gContains(cell, end)   # not touching the border.
        
        # Work out which of the three conditions we have here (passing through, starting, ending)
        
        if (!start.within & !end.within) { # PASES THROUGH
          # If neither the start point nor end point are within the cell then the line passes through it.
          if (plot) { plot(cell,border='blue', add=T)}
          # Work out which compass direction the cell has come from and where it is going to 
          #came.from[XXXX] <- came.from[XXXX] + 1
          #going.to[XXXX]  <- going.to[XXXX] + 1
          
  
        } else if (start.within & end.within) { # WHOLLY CONTAINED
          # If both start and end points are within the cell then the line is wholly contained within the cell
          wholly.contained <- wholly.contained + 1
          if (plot) {plot(cell,col='red', add=T) }
          
        } else if (start.within) { # BEGINS
          # If the start point is within the cell then the line begins here
          if (plot) {plot(cell, col=rgb(0,1,0,0.5), add=T) }
          # Work out which compass direction the cell is going to
          #going.to[XXXX] <- going.to[XXXX] + 1
          starting.count <- starting.count + 1
          
        } else if (end.within) { # ENDS
          # If the end point is within the cell then the line ends here
          if (plot) { plot(cell, col=rgb(1,0,0,0.5), add=T) }
          # Work out which compass direction the cell has come from
          #came.from[XXXX] <- came.from[XXXX] + 1
          ending.count <- ending.count + 1
        }
      
      } # for linesegments
      
    }# for lines in cell

  } # if !is.null (the cell has lines)
 
  # Return the cell, and all the information about lines passing through it
  return(list(
    "cell"=cell,
    "came.from"=came.from,
    "going.to"=going.to,
    "starting.count"=starting.count,
    "ending.count"=ending.count,
    "wholly.contained"=wholly.contained)
  )
}



make.transition.matrix <- function(the.grid, the.traces, plot=TRUE) {
  
  if (plot) {
    plot(the.grid, border='black')
    #polygonsLabel(the.grid, paste('(',grid2$CellX,',',grid2$CellY,')', sep=""), cex=0.4 )
    lines(the.traces)
  }
  
  # First make a list of the individual cells 
  cells <- lapply(seq(1,length(the.grid)), FUN = function(i,g) { return(g[i,]) }, g=the.grid)
  
  # Now have each cell find out about the lines passing through it. 
  # This will return a list of cells and counts of relevant lines.
  results.cells <- lapply(cells, FUN=f, the.traces=the.traces, plot=plot)
           
  #XXXX HERE
  
} # function make.transition.matrix

```

