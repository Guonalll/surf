{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Kalman Filter Data Assimilation Example\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This is the example presented at the ESSA [Social Simulation Conference (SSC)](http://www.sim2017.com/) on 26th September 2017 in Dublin. It shows how to use an Ensemble Kalman Filter (EnKF) to assimilate data into a simple agent-based model. I can't take any credit for the code, it was written entirely by Alice Tapper and [Jon Ward](http://www1.maths.leeds.ac.uk/~jaward/); I've only adapted and commented it.\n",
    "\n",
    "The slides explaining the work are available on the [Simulating Urban Flows\n",
    "website](http://surf.leeds.ac.uk/p/2017-09-26-essa-da.html) and the full paper is available <a href=\"http://surf.leeds.ac.uk/p/2017-09-26-essa-da.pdf\">here</a>.\n",
    "\n",
    "The code below makes use of the [workingcameras.py](./workingcameras.py) model. This is a simple model in which agents start at one end of a hypothetical street and walk towards the other end. Some of them are able to leave the street half way along. There are hypotehtical cameras at each end of the street that count how many people enter and leave, but we don't know how many leave at the midpoint. The purpose of the EnKF is to take the latest counts from the second camera and use this to estimate the real number of people currently in the street.\n",
    "\n",
    "This example begins with running one step of the process to demonstrate how it works before running the whole process a number of times.\n",
    "\n",
    "Please note that you will need the packages `pandas` and `pillow`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation\n",
    "\n",
    "Load the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import workingcameras as cam # The model\n",
    "np.random.seed(3)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate hypothetical 'truth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we generate the 'true' data. We will pretent that this represents the real world system. Use 7200 minutes for no real reason, and choose a probability of agents leaving the street at the midpoint (the 'bleed out rate') drawn from a normal distribution of 0.5, standard deviation 0.1. Start with 600 agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleedout rate is: 0.6788628473430318\n",
      "finished saving camera counts\n"
     ]
    }
   ],
   "source": [
    "bleedoutrate_true = np.random.normal(0.5, scale=0.1)\n",
    "print(\"Bleedout rate is: {}\".format(bleedoutrate_true))\n",
    "truth = cam.runProgramTrue(bleedoutrate_true, 7200, 600) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create the ensemble\n",
    "\n",
    "The 'ensemble' is the group of models that we run simultaneously. For now use an ensemble of size 30 for speed, but ultimately maybe 100 will work better.\n",
    "\n",
    "Initialise the ensemble drawing the bleed out rate from the prior normal distribution,\n",
    "mean 0.5 and SD 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished saving camera counts\n",
      "finished saving camera counts\n",
      "finished saving camera counts\n",
      "finished saving camera counts\n",
      "finished saving camera counts\n",
      "finished saving camera counts\n",
      "finished saving camera counts\n",
      "finished saving camera counts\n",
      "finished saving camera counts\n",
      "finished saving camera counts\n",
      "finished saving camera counts\n",
      "finished saving camera counts\n",
      "finished saving camera counts\n",
      "finished saving camera counts\n",
      "finished saving camera counts\n",
      "finished saving camera counts\n",
      "finished saving camera counts\n",
      "finished saving camera counts\n",
      "finished saving camera counts\n",
      "finished saving camera counts\n",
      "finished saving camera counts\n",
      "finished saving camera counts\n",
      "finished saving camera counts\n",
      "finished saving camera counts\n",
      "finished saving camera counts\n",
      "finished saving camera counts\n",
      "finished saving camera counts\n",
      "finished saving camera counts\n",
      "finished saving camera counts\n",
      "finished saving camera counts\n"
     ]
    }
   ],
   "source": [
    "initial = []\n",
    "\n",
    "for i in range(30):\n",
    "    bleedoutrate = np.random.normal(0.5, scale=0.1)\n",
    "    result = cam.runProgram(bleedoutrate, 61, 600)\n",
    "    initial.append(result)\n",
    "\n",
    "initial = np.array(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the spread in bleedoutrates across the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.54365099,  0.50964975,  0.31365073,  0.47226118,  0.4645241 ,\n",
       "        0.49172585,  0.43729993,  0.49561818,  0.4522782 ,  0.36861352,\n",
       "        0.58846224,  0.5881318 ,  0.67095731,  0.50500336,  0.45953226,\n",
       "        0.44546401,  0.34535227,  0.59823674,  0.38989324,  0.38149535,\n",
       "        0.47943501,  0.64861484,  0.52367163,  0.39762149,  0.42870068,\n",
       "        0.5625245 ,  0.48394866,  0.42311636,  0.47699693,  0.57450563])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial[:, -3] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast Step\n",
    "\n",
    "In the 'forecast' step, the current (estimated) model state is fed into the model, and the model plays forward until the next observation time (1 hour in this case). This generates a forecast. \n",
    "\n",
    "The ensemble forecast mean will give an estimated forecast of the true state, while the covariance of the ensemble forecast states provides a measure of its uncertainty.\n",
    "\n",
    "Now step each model in the ensemble by running them forward for an hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "finished saving camera counts\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "finished saving camera counts\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "finished saving camera counts\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "finished saving camera counts\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "finished saving camera counts\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "finished saving camera counts\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "finished saving camera counts\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "finished saving camera counts\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "finished saving camera counts\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "finished saving camera counts\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "finished saving camera counts\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "finished saving camera counts\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "finished saving camera counts\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "finished saving camera counts\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "finished saving camera counts\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "finished saving camera counts\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "finished saving camera counts\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "finished saving camera counts\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "finished saving camera counts\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "finished saving camera counts\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "finished saving camera counts\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "finished saving camera counts\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "finished saving camera counts\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "finished saving camera counts\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "finished saving camera counts\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "finished saving camera counts\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "finished saving camera counts\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "finished saving camera counts\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "finished saving camera counts\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "finished saving camera counts\n"
     ]
    }
   ],
   "source": [
    "forecasts = []\n",
    "\n",
    "for i in range(30):\n",
    "    prediction = cam.runForecast(61, 600, initial[i], 0, 0, 0, steps=60)\n",
    "    forecasts.append(prediction)\n",
    "    \n",
    "forecasts = np.array(forecasts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the covariance matrix\n",
    "\n",
    "We now generate the forecast covariance matrix. This is used to provide a measure of the uncertainty of the ensemble forecasts.\n",
    "\n",
    "The covariance matrix is an N x N matrix, where:\n",
    " - N = M agents locations and route info + bleedoutrate + c_a counts + c_b counts,\n",
    " - i.e N = 2M + 3\n",
    "\n",
    "We find the mean of the forecast ensemble, and find the error from the mean for each value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "means = np.mean(forecasts, axis=0)\n",
    "adjusted = forecasts - means\n",
    "covariance = np.cov(adjusted.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The covariance[-1][-3] measures how the change in bleed out rate affects\n",
    "the change in the c_b counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.730948154486\n"
     ]
    }
   ],
   "source": [
    "print(covariance[-1][-3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Assimilation Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon receiving the actual observation from our 'truth' data, the ensemble forecasts are updated accordingly.  The updated values are called the ensemble analysis. As before, the ensemble analysis mean will give the best estimation of the true state, while the covariance of the ensemble analysis states provides a measure of its uncertainty.\n",
    "\n",
    "Start by getting the next observation from our truth data (these are counts from the two cameras).\n",
    "\n",
    "### Prepare virtual and 'real' observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99, 73]\n"
     ]
    }
   ],
   "source": [
    "observation = [truth[-2][2], truth[-1][2]]\n",
    "print(observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create the virtual observations by assuming additive Gaussian noise (in the real world sensors will never produce 100% accurate estimates of the state of the world, so we assume that our measurements contain some noise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  91.25373948   58.6000573 ]\n",
      " [ 104.65942851   64.37937369]\n",
      " [  97.35818499   83.186074  ]\n",
      " [  86.16844247   68.49690888]\n",
      " [ 131.37224013   86.11428584]\n",
      " [  79.59695052   71.80388593]\n",
      " [ 107.46728277   91.50206567]\n",
      " [ 101.23479592   65.04126783]\n",
      " [  88.04210034   82.67592977]\n",
      " [ 103.69590561   65.25028113]\n",
      " [  96.163925     66.75702977]\n",
      " [ 109.86986487   62.65058984]\n",
      " [ 106.29621713   85.77278426]\n",
      " [ 106.29373989   60.48640224]\n",
      " [ 119.17488685   62.82680981]\n",
      " [ 105.39652612   61.6999781 ]\n",
      " [  72.83834624   76.38625399]\n",
      " [ 103.30552747   71.83838559]\n",
      " [ 103.14102746   63.27383668]\n",
      " [  87.93802744   70.47864852]\n",
      " [ 127.63915214   85.22221812]\n",
      " [  91.20012369   81.38069807]\n",
      " [  91.82453009   66.14108819]\n",
      " [ 111.88926012   65.12103032]\n",
      " [  73.86548049   59.40257949]\n",
      " [ 100.32622809   74.92011732]\n",
      " [ 117.62424777   62.25961304]\n",
      " [ 109.97198604   79.38950125]\n",
      " [  96.76479342   85.53765853]\n",
      " [ 106.38178354   60.0653727 ]]\n"
     ]
    }
   ],
   "source": [
    "virtualobs = np.zeros((30,2))\n",
    "\n",
    "for i in range(30):\n",
    "    for j in range(2):\n",
    "        virtualobs[i][j] = observation[j] + np.random.normal(0, 15)\n",
    "\n",
    "print(virtualobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kalman Gain Matrix\n",
    "\n",
    "Code the matrix H, the forward model, which is just a transformation matrix changing the state vector into the same form as the observation vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H = np.zeros((2, 2*600 + 3))\n",
    "\n",
    "H[-1][-1] = 1\n",
    "H[0][-2] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the **Kalman gain matrix**. This is used to balance the impact of the new data on the model states as the real world state should be some combination of an imperfect model and the imperfect real world observations.\n",
    "\n",
    "R contains the variance of the random errors (i.e 15^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P = covariance\n",
    "R = np.array([[225, 0],[0, 225]])\n",
    "\n",
    "tbi = np.dot(np.dot(H,P),H.T) + R # (tbi = 'to be inverted')\n",
    "\n",
    "# We want to solve K tbi = P H.T to find K \n",
    "# rewrite to form tbi.T K.T = H P.T'''\n",
    "\n",
    "LHS = tbi.T\n",
    "RHS = np.dot(H,P.T)\n",
    "\n",
    "Ktranspose = np.linalg.lstsq(LHS,RHS)\n",
    "\n",
    "K = Ktranspose[0].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ensemble analysis\n",
    "\n",
    "Create the ensemble analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_analysis = []\n",
    "\n",
    "for i in range(30):\n",
    "    tbm = virtualobs[i] - np.dot(H,forecasts[i])\n",
    "    adjust = forecasts[i] + np.dot(K,tbm)\n",
    "    ens_analysis.append(adjust)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average the ensemble analysis and find analysis covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ens_means = np.mean(ens_analysis, axis=0)\n",
    "\n",
    "ens_error = ens_analysis - ens_means\n",
    "\n",
    "ens_covariance = np.cov(ens_error.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! We can now just repeat that process for as many iterations as we want to.\n",
    "\n",
    "Finish by looking at the ensemble means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': [<matplotlib.lines.Line2D at 0x11bf91c50>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x11dfd5f98>,\n",
       "  <matplotlib.lines.Line2D at 0x11dfe15f8>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x11dfe1d30>],\n",
       " 'means': [],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x11dfe1710>],\n",
       " 'whiskers': [<matplotlib.lines.Line2D at 0x11bf91e10>,\n",
       "  <matplotlib.lines.Line2D at 0x11dfd5978>]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJBXKAEhSoQyAJBXKAEhSof4fkA9H3gKqB58AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d00c5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(ens_means, notch=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
