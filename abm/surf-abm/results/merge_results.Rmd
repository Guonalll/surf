---
title: "Analysing surf results across multiple runs."
author: "Nick Malleson"
date: '`r format(Sys.time(), "%d %B, %Y (%H:%M)")`'
output:
  html_document: 
    toc: yes
    pandoc_args: [
      "+RTS", "-K64m",
      "-RTS"
    ]
  pdf_document:
    fig_crop: no
    highlight: kate
    keep_tex: yes
    latex_engine: xelatex
    number_sections: yes
fontsize: 10pt
---


```{r initialise, echo=FALSE, message=FALSE, warning=FALSE}
library(GISTools)
#library(rgeos)    # For things like gIntersects
#library(rgdal)     # For reading shapefiles
#library(raster)    # For creating regular grids
#library(plyr)     # For counting and aggregating
#library(tmap)     # For thematic maps
library(classInt) # Jenks natural breaks
#library(png)      # For loading pngs after they have been written
#library(grid)     # so that they can be embedded in knitted documents
#library(spdep)    # For doing the spatial regression, contiguity matrices, etc.
#library(GWmodel)  # For geographically weighted regression (GWR)
#library(MASS)     # For stepwise regression (stepAIC())
#library(pander)   # For printing tables nicely
#library(MVN)      # For testing for multivariate normality (MVN)
library(RColorBrewer) # For making nice colour themes
#library(rgl)       # For 3D space-time cube
#library(plot3D)    # For 3D space-time cube
library(dplyr)     # To look up fields in tables (e.g. N rows higher --> lag)
library(parallel)
library(pbapply)  # For progress bar in parallel
no_cores <- detectCores() / 2  # Detect the number of cores that are available and use half (often CPUs simulate 2 threads per core)
Sys.setenv(MC_CORES=no_cores) # Run on n cores (I'm not sure which of these
options("mc.cores"=no_cores) # is correct).
library(lubridate)
library(hexbin)   # For hex bins
library(ggplot2)  # ditto
library(gridExtra) # For arranging two grids side by side
library(feather)  # For reading data prepared by python
```

Set up the directories. Note: The script needs the `noggin_data.feather` file to be in the working directory. This is generated by the data and scripts in:

`~/mapping/projects/frl/otley/noggin_data`

```{r get.directories }

SCENARIO <- "ABBF-otley" # The name of the scenario to analyse
# The ID of the agent to analyse (graphs of all agents can be difficult to understand). If -1 then do a few at random
AGENT_ID <- -1
#AGENT_ID <- 1

# When running this script directly in R(Studio) we need to specify the current working directory
CURRENT_DIRECTORY <- '/Users/nick/research_not_syncd/git_projects/surf/abm/surf-abm/results'

#CURRENT_DIRECTORY <- "C:/Code/surf/abm/surf-abm/results"
setwd(CURRENT_DIRECTORY) # This is only required when running directly in R(Studio)

# Find the directories of all the model runs
scenarios <- sort(list.files(paste0("./out/",SCENARIO))) # The IDs of each run
scenarios.dirs <- vapply(X = scenarios, FUN = function(x) {paste(paste0("./out/",SCENARIO), "/", x, sep="") }, FUN.VALUE = character(1))
```

Will analyse the `r length(scenarios)` scenarios in `r SCENARIO`

# Read and prepare the data

Read the data on the agent locations and activities as well as the camera counts and put into big tables


```{r readData}

# TODO - include a unique id (the scenario) for each model

# Read the first result to make the tables. The add append the remaining results
agents  <- read.csv(paste0(scenarios.dirs[1],'/agents.csv'))
acts    <- read.csv(paste0(scenarios.dirs[1],'/agent-activities.csv'))
cameras <- read.csv(paste0(scenarios.dirs[1],'/camera-counts.csv'))


# Now append the remaining results
for (i in 2:length(scenarios)) {
  s <- scenarios[i]
  dir <- scenarios.dirs[i]
  agents.temp  <- read.csv(paste0(scenarios.dirs[1],'/agents.csv'))
  acts.temp    <- read.csv(paste0(scenarios.dirs[1],'/agent-activities.csv'))
  cameras.temp <- read.csv(paste0(scenarios.dirs[1],'/camera-counts.csv'))
  agents  <- rbind(agents, agents.temp)
  acts    <- rbind(acts, acts.temp)
  cameras <- rbind(cameras, cameras.temp)
#  print(paste("Read file",i))
}
rm(agents.temp, acts.temp, cameras.temp, s, dir)

# Make proper time columns (sorry, this looks complicated because it's in parallel, but simply uses 'strptime' to convert the dates) . 
# The do.call is because unlist breaks lists of dates (https://stackoverflow.com/questions/15659783/why-does-unlist-kill-dates-in-r)
# Text format for agents and activities is "2011-01-01T01:10"
agents$date  <- do.call("c", pblapply( X = 1:nrow(agents), FUN = function(i) { strptime(as.character(agents[i,"Time"]), "%Y-%m-%dT%H:%M") }, cl=no_cores ) )
gc()
acts$date    <- do.call("c", pblapply( X = 1:nrow(acts),   FUN = function(i) { strptime(as.character(  acts[i,"Time"]), "%Y-%m-%dT%H:%M") }, cl=no_cores/2 ) )
gc()

# Camera dates need to have date plus number of hours as these are stored in different columns (don't bother with parallel)
cameras$date <- as.POSIXct(as.Date(cameras$Date)) + ( 3600 * cameras$Hour )
# Cameras also need some extra date columns to make them easier to work with
cameras$Day = as.POSIXct(round(cameras$date, units="days" ))
#hour = as.POSIXct(round(modelDf$datetime, units="hours"))
cameras$Week =    week(cameras$date) # (from lubridate library)
cameras$Month =   month(cameras$date)
cameras$Weekday = weekdays(cameras$date)

# Make the camera ID a string so that ggplot2 treats it as cetegorical
cameras$Camera <- paste0("",cameras$Camera)


# Read the real camera counts. These data were prepared by scripts and data in: ~/mapping/projects/frl/otley/noggin_data
noggin <- read_feather("noggin_data.feather")
noggin$datetime <- as.POSIXct(noggin$Timestamp)
noggin$Location <- paste0("",noggin$Location) # ID -> String
noggin$Day   <-   as.POSIXct(round(noggin$datetime, units="days" ))
noggin$Hour  <-   as.POSIXct(round(noggin$datetime, units="hours"))
noggin$Week  <-   floor_date(noggin$datetime, "week") # (from lubridate library)
noggin$Month <-   floor_date(noggin$datetime, "month")
noggin$Weekday <- weekdays(noggin$datetime)
noggin$HourOfDay <- as.integer(format(noggin$datetime, "%H")) # (https://stackoverflow.com/questions/10683224/obtain-hour-from-datetime-vector)
# Extract middle of the week
noggin = noggin[which( !(noggin$Location %in% c("16","19")) & noggin$Weekday %in% c("Tuesday","wednesday","Thursday") ),]
noggin[which(noggin$Location=="20"),]$Location = "17" # rename location 20 to location 17 (as per noggin metadata)
#aggnoggin = aggregate(Count~Location + HourOfDay, data=noggin, FUN=sum)
#aggnoggin$RelCount = aggnoggin$Count / sum(aggnoggin$Count)

save.image("temp.RData")

```


Choose one day from which to do the remaining analysis.

XXXX CHOOSE DAY 5/6 - but need to do longer runs.

```{r choose.day}
# Sanity check
stopifnot(identical(unique(date(cameras$date)), unique(date(agents$date))) & identical(unique(date(cameras$date)), unique(date(acts$date))))

analysis.day <- as.Date("2011-01-03")

cameras <- cameras[date(cameras$date)==analysis.day,]
acts    <-    acts[date(acts$date)   ==analysis.day,]
agents  <-  agents[date(agents$date) ==analysis.day,]

stopifnot(identical(unique(date(cameras$date)), unique(date(agents$date))) & identical(unique(date(cameras$date)), unique(date(acts$date))))
stopifnot(length(unique(date(cameras$date)))==1)
```

# Plot model results 

Plot the total average hourly footfall count and 99% confidence intervals. Note that the confidence intervals are so small that they are not visible.

```{r plot.hourly.total, fig.width=9, fig.height=5}
#ggplot(cameras, aes(Hour, Count, color=Camera)) + # Colouring points by camera id (doesn't work)
#ggplot(cameras[sample(1:nrow(cameras), 1000),], aes(Hour, Count)) + # Sampling N points from the cameras shows wider confidence interval (obviously)
ggplot(cameras, aes(Hour, Count)) +
  geom_hex(bins=20) +
  #geom_point() + 
  geom_smooth(method="loess", se=TRUE, level=0.99, color="green") + 
  geom_smooth(se=TRUE, level=0.99, color="purple") + #GAM
  ggtitle( "Total footfall count from all cameras over all model runs")


```

Plot the average hourly count per camera, again with confindence intervals.

```{r plot.hourly.cameras, fig.width=9, fig.height=5 }

ggplot(cameras, aes(Hour, Count, col=Camera)) +
  #geom_hex(bins=20) +
  geom_point() + 
  #geom_smooth(method="loess", se=TRUE, level=0.99) + #loess
  geom_smooth(se=TRUE, level=0.99) + 
  ggtitle( "Footfall counts per camera over all model runs")

```

# Plot Real Data

Compare these to the real data

```{r compare.plots, fig.width=9, fig.height=5 }

plot1 <- ggplot(noggin, aes(HourOfDay, Count)) +
  geom_hex(bins=20) +
  geom_smooth(method="loess", se=TRUE, level=0.99, color="green") + 
  geom_smooth(se=TRUE, level=0.99, color="purple") + #GAM
  ggtitle( "Total footfall count from all cameras (real data)")

plot2 <- ggplot(noggin, aes(HourOfDay, Count, col=Location)) +
  geom_point() + 
  geom_smooth(se=TRUE, level=0.99) + #GAM
  ggtitle( "Total footfall count per cameras (real data)")

grid.arrange(plot1, plot2, ncol=2)

#ylab="Total Count"
#plot(aggregate(Count~HourOfDay, data=aggnoggin, FUN=sum), 
#     main="Footfall per hour of day (observations middle of week)", ylab=ylab, col="black", type="l"
#)
```




# Plot Differences Between the Model and the Real Data

```{r}

# Summarise per camera and hour
#cameras.agg = aggregate(Count~Camera + HourOfDay, data=camera, FUN=sum)
#aggModelDf$RelCount = aggModelDf$Count / sum(aggModelDf$Count)


XXXX HERE NEED AVERAGE COUNTS, PER DAY, THEN CAN START TO DRAW CONFIDENCE INTERVALS


# Find all of the activities - useful throughout
all.acts <- unique(agents$Activity)
# Also find the active activities (i.e. all not including 'none', as None doesn't have any intensities)
active.acts <- unique(acts$Activity)



# Remove any agents that we're not plotting the results for. Graphs easily become overcomplicated
#agent.ids <- c() # The agents to plot
#if (AGENT_ID == -1) { # Plot a selection of agents chosen at random
#  agent.ids <- sample(unique(acts$Agent), size=10, replace=FALSE) # sample from all ids
#} else {
#  # Otherwise just plot the one agent
#  agent.ids <- c(AGENT_ID)
#}
#agents <- agents[which(agents$Agent %in% agent.ids),]
#acts <- acts[which(acts$Agent %in% agent.ids),]





```

Look at the footfall at different cameras across all of the runs.

XXXX HERE. 

```{r plotCameraCounts-hexbin}



```

```{r plotCameraCounts-hexbin}

ggplot(cameras, aes(Hour, Count)) +
  geom_hex(bins=20) + 
  geom_smooth() + 
  ggtitle( "Footfall counts over all runs")



```






Plot just the overall intensities of the different activities for some agents.

```{r plotOverallActivity}

# Plot
for (id in agent.ids) {
  par(mfrow=c(1,1))
  i <- 1 # For colours
  for (activity in active.acts) {
    if (i==1) { # First plot
      # Plot overall intensity
      plot(x=acts[which(acts$Activity==activity & acts$Agent==id),]$Iterations,
           y=acts[which(acts$Activity==activity & acts$Agent==id),]$Intensity, 
           type='o', col=i, 
           ylim=c(0,max(acts$Intensity)), # All charts have same y axis
           #ylim=c(0,max(acts[which(acts$Activity==activity & acts$Agent==id),]$Intensity)), # Y axis different for each agent
           pch=1,
           xlab = "Time", ylab="TotalIntensity", main=paste("Activities for agent",id))
    } else { # Now for the remaining activities
      points(
        x=acts[which(acts$Activity==activity & acts$Agent==id),]$Iterations, 
        y=acts[which(acts$Activity==activity & acts$Agent==id),]$Intensity, type='o', col=i )
    }
    # Add a vertical line when a new CurrentActivity starts (with the colour of that new activity)
    abline(v=acts[which(
      acts$Activity==activity & acts$CurrentActivity==1 & 
        dplyr::lag(acts$CurrentActivity, length(active.acts)*length(agent.ids)) != 1 & 
        acts$Agent==id)
      ,]$Iterations, col=i, lwd=2)
    
    i <- i + 1 # increment the colour counter (one colour per activity)
    j<- 1 # Reset the point type counter - same point type for each kind of intensity (total, background, time)
  }
  
  legend("topleft", legend=active.acts, col=1:length(active.acts), lty=1, pch="o")
}

```

Boxplots for the different intensities of different activities

```{r activityBoxplots }

par(mfrow=c(length(active.acts),3))

for (id in agent.ids) {
  for (activity in active.acts) {
    for (type in c("Intensity", "BackgroundIntensity", "TimeIntensity")) {
      boxplot(acts[which(acts$Activity==activity & acts$Agent==id),type], main=paste(activity,"Agent",id), ylab=type)
    }
  }
}
  
```


Plot all the intensities of the different activities in one chart.

```{r plotActivitiesInOne}

par(mfrow=c(1,1))

for (id in agent.ids) {
  # Plot
  i <- 1 # For colours
  for (activity in active.acts) { # Find the activity with the highest overall intensity. That needs to be plotted first
    if (i==1) { # First plot
      # Plot overall intensity
      plot(x=acts[which(acts$Activity==activity & acts$Agent==id),]$date,
           y=acts[which(acts$Activity==activity & acts$Agent==id),]$Intensity,
           type='p', col=i, ylim=c(0,max(acts$Intensity)), pch=1,
           xlab = "Time", ylab="TotalIntensity", main=paste("Intensities for agent",id))
      # Backgruound intesity
      points(
        x=acts[which(acts$Activity==activity & acts$Agent==id),]$date,
        y=acts[which(acts$Activity==activity & acts$Agent==id),]$BackgroundIntensity, 
        type='p', col=i, pch=2)
      # Time intensity
      points(
        x=acts[which(acts$Activity==activity & acts$Agent==id),]$date,
        y=acts[which(acts$Activity==activity & acts$Agent==id),]$TimeIntensity, 
        type='p', col=i, pch=3)
    } else { # Now for the remaining activities
      points(x=acts[which(acts$Activity==activity & acts$Agent==id),]$date,
             y=acts[which(acts$Activity==activity & acts$Agent==id),]$Intensity, type='p', col=i, pch=1)
      points(x=acts[which(acts$Activity==activity & acts$Agent==id),]$date, 
             y=acts[which(acts$Activity==activity & acts$Agent==id),]$BackgroundIntensity, type='p', col=i, pch=2)
      points(x=acts[which(acts$Activity==activity & acts$Agent==id),]$date, 
             y=acts[which(acts$Activity==activity & acts$Agent==id),]$TimeIntensity, type='p', col=i, pch=3)
      
    }
    i <- i + 1 # increment the colour counter (one colour per activity)
    j<- 1 # Reset the point type counter - same point type for each kind of intensity (total, background, time)
  } # for activities
  
  legend("topleft", legend=active.acts, col=1:length(active.acts), lty=1, pch="o")
  legend("topright", legend=c('Overall','Background','Time'), col=1, lty=1, pch=1:3)

} # for agent ids

```

Plot the intensities of the different activities, but on different plots.

```{r plotActivitiesMultiplePlots}

par(mfrow=c(length(active.acts),1))

for (id in agent.ids) {

  # Plot
  i <- 1 # For colours
  for (activity in active.acts) { # Find the activity with the highest overall intensity. That needs to be plotted first
    # Plot overall intensity
    plot(x=acts[which(acts$Activity==activity & acts$Agent==id),]$date,
         y=acts[which(acts$Activity==activity & acts$Agent==id),]$Intensity,
         type='p', col=i, ylim=c(0,max(acts$Intensity)), pch=1, xlab = "Time", ylab="Intensity", main=paste("Agent",id,activity) 
         )
    # Backgruound intesity
    points(x=acts[which(acts$Activity==activity & acts$Agent==id),]$date,
           y=acts[which(acts$Activity==activity & acts$Agent==id),]$BackgroundIntensity,
           type='p', col=i, pch=2
           )
    # Time intensity
    points(x=acts[which(acts$Activity==activity & acts$Agent==id),]$date,
           y=acts[which(acts$Activity==activity & acts$Agent==id),]$TimeIntensity, 
           type='p', col=i, pch=3
           )
    legend("topright", legend=c('Overall','Background','Time'), col=1, lty=1, pch=1:3)
      
    i <- i + 1 # increment the colour counter (one colour per activity)
    j<- 1 # Reset the point type counter - same point type for each kind of intensity (total, background, time)
  }
  
} # for agent ids

```



Map the agent locations in 2D and 3D with some additional analysis

```{r plotAgentLocations.2D, fig.width=10, fig.height=10 }

# TEMPORARILY PLOT ALL
#agent.ids <- unique(acts$Agent)

# Calculat euclidean distance
euc.dist <- function(p1, p2) sqrt( ( p1[,1] - p2[,1] )**2 + ( p1[,2] - p2[,2] )**2 ) 

for (id in agent.ids) {
  
  par(mfrow=c(2,2))
  
  # 2D & 3D PLOTS

  # Data for the agent in question
  single.agent <- agents[agents$Agent==id,]
  
  single.agent.coords = cbind(single.agent$x, single.agent$y)
  single.agent.spdf = SpatialPointsDataFrame(single.agent.coords, single.agent)
  
  # Shading for the time of each location (2D)
  shades <- shading(
      classIntervals(single.agent$Iterations, n = 8, style = 'kmeans')$brks,
      cols=brewer.pal(9,'Reds')
  )
  
  # Colour for the 3D plot, depends on activity. Need to add another column with activity as a number
  act.colours <- data.frame("act"=as.character(all.acts), "colour" = seq(1:length(all.acts)))
  # Now work out which colour goes with which activity
  colours <- base::merge(x=single.agent, y=act.colours, by.x="Activity", by.y="act" , all.x=TRUE, all.y=FALSE)
  colours <- colours[order(colours$Iteration),] # merge randomises the order; put it back
  single.agent$colour <- colours$colour
  
    # Draw 2D and 3D plots
  choropleth(single.agent.spdf, single.agent.spdf$Time, shading = shades, main=paste("Agent",id))
  plot3D::points3D(x=single.agent$x, y=single.agent$y, z=single.agent$Iterations, col=single.agent$colour)
  legend("topleft",legend=act.colours$act, col=act.colours$col, pch='o', cex=1.0)
  
  # BOXPLOTS OF DISTANCES
  # Look at the distances travelled by the agent in each iteration to find unusual jumps
  # Two lists of points to calculate the distances between
  points1 <- head(single.agent.coords, -1)  # Drop last row
  points2 <- tail(single.agent.coords, -1) # Drop first row
  dists <- euc.dist(points1, points2)
  boxplot(dists)
}

```





